# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

# Tests for tree explain



statement ok
set datafusion.explain.format = "tree";

########  Setup Data Files #######

# table1: CSV
query I
COPY (VALUES (1, 'foo', 1, '2023-01-01'), (2, 'bar', 2, '2023-01-02'), (3, 'baz', 3, '2023-01-03'))
TO 'test_files/scratch/explain_tree/table1.csv';
----
3

statement ok
CREATE EXTERNAL TABLE table1 (
  int_col INT,
  string_col TEXT,
  bigint_col BIGINT,
  date_col DATE
)
STORED AS CSV
LOCATION 'test_files/scratch/explain_tree/table1.csv';

# table2: Parquet
query I
COPY (SELECT * from table1)
TO 'test_files/scratch/explain_tree/table2.parquet'
----
3

statement ok
CREATE EXTERNAL TABLE table2
STORED AS PARQUET
LOCATION 'test_files/scratch/explain_tree/table2.parquet';


# table3: Memory
statement ok
CREATE TABLE table3 as select * from table1;

# table4: JSON
query I
COPY (SELECT * from table1)
TO 'test_files/scratch/explain_tree/table4.json'
----
3

statement ok
CREATE EXTERNAL TABLE table4
STORED AS JSON
LOCATION 'test_files/scratch/explain_tree/table4.json';

# table5: ARROW
query I
COPY (SELECT * from table1)
TO 'test_files/scratch/explain_tree/table5.arrow'
----
3

statement ok
CREATE EXTERNAL TABLE table5
STORED AS ARROW
LOCATION 'test_files/scratch/explain_tree/table5.arrow';

statement ok
CREATE UNBOUNDED EXTERNAL TABLE annotated_data_infinite2 (
  a0 INTEGER,
  a INTEGER,
  b INTEGER,
  c INTEGER,
  d INTEGER
)
STORED AS CSV
WITH ORDER (a ASC, b ASC, c ASC)
LOCATION '../core/tests/data/window_2.csv'
OPTIONS ('format.has_header' 'true');

statement ok
CREATE TABLE hashjoin_datatype_table_t1_source(c1 INT, c2 BIGINT, c3 DECIMAL(5,2), c4 VARCHAR)
AS VALUES
(1,    86400000,  1.23,    'abc'),
(2,    172800000, 456.00,  'def'),
(null, 259200000, 789.000, 'ghi'),
(3,    null,      -123.12, 'jkl')
;

statement ok
CREATE TABLE hashjoin_datatype_table_t1
AS SELECT
  arrow_cast(c1, 'Date32') as c1,
  arrow_cast(c2, 'Date64') as c2,
  c3,
  arrow_cast(c4, 'Dictionary(Int32, Utf8)') as c4
FROM
  hashjoin_datatype_table_t1_source

statement ok
CREATE TABLE hashjoin_datatype_table_t2_source(c1 INT, c2 BIGINT, c3 DECIMAL(10,2), c4 VARCHAR)
AS VALUES
(1,    86400000,  -123.12,   'abc'),
(null, null,      100000.00, 'abcdefg'),
(null, 259200000, 0.00,      'qwerty'),
(3,   null,       789.000,   'qwe')
;

statement ok
CREATE TABLE hashjoin_datatype_table_t2
AS SELECT
  arrow_cast(c1, 'Date32') as c1,
  arrow_cast(c2, 'Date64') as c2,
  c3,
  arrow_cast(c4, 'Dictionary(Int32, Utf8)') as c4
FROM
  hashjoin_datatype_table_t2_source

######## Begin Queries ########

# Filter
query TT
explain SELECT int_col FROM table1 WHERE string_col != 'foo';
----
physical_plan
01)┌───────────────────────────┐
02)│    CoalesceBatchesExec    │
03)└─────────────┬─────────────┘
04)┌─────────────┴─────────────┐
05)│         FilterExec        │
06)│    --------------------   │
07)│         predicate:        │
08)│    string_col@1 != foo    │
09)└─────────────┬─────────────┘
10)┌─────────────┴─────────────┐
11)│      RepartitionExec      │
12)│    --------------------   │
13)│  output_partition_count:  │
14)│             1             │
15)│                           │
16)│    partitioning_scheme:   │
17)│     RoundRobinBatch(4)    │
18)└─────────────┬─────────────┘
19)┌─────────────┴─────────────┐
20)│       DataSourceExec      │
21)│    --------------------   │
22)│          files: 1         │
23)│        format: csv        │
24)└───────────────────────────┘

# Aggregate
query TT
explain SELECT string_col, SUM(bigint_col) FROM table1 GROUP BY string_col;
----
physical_plan
01)┌───────────────────────────┐
02)│       AggregateExec       │
03)│    --------------------   │
04)│           aggr:           │
05)│   sum(table1.bigint_col)  │
06)│                           │
07)│         group_by:         │
08)│ string_col@0 as string_col│
09)│                           │
10)│           mode:           │
11)│      FinalPartitioned     │
12)└─────────────┬─────────────┘
13)┌─────────────┴─────────────┐
14)│    CoalesceBatchesExec    │
15)└─────────────┬─────────────┘
16)┌─────────────┴─────────────┐
17)│      RepartitionExec      │
18)│    --------------------   │
19)│  output_partition_count:  │
20)│             4             │
21)│                           │
22)│    partitioning_scheme:   │
23)│  Hash([string_col@0], 4)  │
24)└─────────────┬─────────────┘
25)┌─────────────┴─────────────┐
26)│       AggregateExec       │
27)│    --------------------   │
28)│           aggr:           │
29)│   sum(table1.bigint_col)  │
30)│                           │
31)│         group_by:         │
32)│ string_col@0 as string_col│
33)│                           │
34)│       mode: Partial       │
35)└─────────────┬─────────────┘
36)┌─────────────┴─────────────┐
37)│      RepartitionExec      │
38)│    --------------------   │
39)│  output_partition_count:  │
40)│             1             │
41)│                           │
42)│    partitioning_scheme:   │
43)│     RoundRobinBatch(4)    │
44)└─────────────┬─────────────┘
45)┌─────────────┴─────────────┐
46)│       DataSourceExec      │
47)│    --------------------   │
48)│          files: 1         │
49)│        format: csv        │
50)└───────────────────────────┘


# Limit
query TT
explain SELECT int_col FROM table1 LIMIT 3,2;
----
physical_plan
01)┌───────────────────────────┐
02)│      GlobalLimitExec      │
03)│    --------------------   │
04)│          limit: 2         │
05)│          skip: 3          │
06)└─────────────┬─────────────┘
07)┌─────────────┴─────────────┐
08)│       DataSourceExec      │
09)│    --------------------   │
10)│          files: 1         │
11)│        format: csv        │
12)└───────────────────────────┘

# 2 Joins
query TT
explain SELECT table1.string_col, table2.date_col FROM table1 JOIN table2 ON table1.int_col = table2.int_col;
----
physical_plan
01)┌───────────────────────────┐
02)│    CoalesceBatchesExec    │
03)└─────────────┬─────────────┘
04)┌─────────────┴─────────────┐
05)│        HashJoinExec       │
06)│    --------------------   │
07)│            on:            ├──────────────┐
08)│  (int_col@0 = int_col@0)  │              │
09)└─────────────┬─────────────┘              │
10)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
11)│    CoalesceBatchesExec    ││    CoalesceBatchesExec    │
12)└─────────────┬─────────────┘└─────────────┬─────────────┘
13)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
14)│      RepartitionExec      ││      RepartitionExec      │
15)│    --------------------   ││    --------------------   │
16)│  output_partition_count:  ││  output_partition_count:  │
17)│             4             ││             4             │
18)│                           ││                           │
19)│    partitioning_scheme:   ││    partitioning_scheme:   │
20)│    Hash([int_col@0], 4)   ││    Hash([int_col@0], 4)   │
21)└─────────────┬─────────────┘└─────────────┬─────────────┘
22)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
23)│      RepartitionExec      ││      RepartitionExec      │
24)│    --------------------   ││    --------------------   │
25)│  output_partition_count:  ││  output_partition_count:  │
26)│             1             ││             1             │
27)│                           ││                           │
28)│    partitioning_scheme:   ││    partitioning_scheme:   │
29)│     RoundRobinBatch(4)    ││     RoundRobinBatch(4)    │
30)└─────────────┬─────────────┘└─────────────┬─────────────┘
31)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
32)│       DataSourceExec      ││       DataSourceExec      │
33)│    --------------------   ││    --------------------   │
34)│          files: 1         ││          files: 1         │
35)│        format: csv        ││      format: parquet      │
36)└───────────────────────────┘└───────────────────────────┘

# 3 Joins
query TT
explain SELECT
  table1.string_col,
  table2.date_col,
  table3.date_col
FROM
  table1 JOIN table2 ON table1.int_col = table2.int_col
         JOIN table3 ON table2.int_col = table3.int_col;
----
physical_plan
01)┌───────────────────────────┐
02)│    CoalesceBatchesExec    │
03)└─────────────┬─────────────┘
04)┌─────────────┴─────────────┐
05)│        HashJoinExec       │
06)│    --------------------   │
07)│            on:            ├───────────────────────────────────────────┐
08)│  (int_col@1 = int_col@0)  │                                           │
09)└─────────────┬─────────────┘                                           │
10)┌─────────────┴─────────────┐                             ┌─────────────┴─────────────┐
11)│    CoalesceBatchesExec    │                             │    CoalesceBatchesExec    │
12)└─────────────┬─────────────┘                             └─────────────┬─────────────┘
13)┌─────────────┴─────────────┐                             ┌─────────────┴─────────────┐
14)│        HashJoinExec       │                             │      RepartitionExec      │
15)│    --------------------   │                             │    --------------------   │
16)│            on:            │                             │  output_partition_count:  │
17)│  (int_col@0 = int_col@0)  ├──────────────┐              │             1             │
18)│                           │              │              │                           │
19)│                           │              │              │    partitioning_scheme:   │
20)│                           │              │              │    Hash([int_col@0], 4)   │
21)└─────────────┬─────────────┘              │              └─────────────┬─────────────┘
22)┌─────────────┴─────────────┐┌─────────────┴─────────────┐┌─────────────┴─────────────┐
23)│    CoalesceBatchesExec    ││    CoalesceBatchesExec    ││       DataSourceExec      │
24)│                           ││                           ││    --------------------   │
25)│                           ││                           ││        bytes: 1560        │
26)│                           ││                           ││       format: memory      │
27)│                           ││                           ││          rows: 1          │
28)└─────────────┬─────────────┘└─────────────┬─────────────┘└───────────────────────────┘
29)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
30)│      RepartitionExec      ││      RepartitionExec      │
31)│    --------------------   ││    --------------------   │
32)│  output_partition_count:  ││  output_partition_count:  │
33)│             4             ││             4             │
34)│                           ││                           │
35)│    partitioning_scheme:   ││    partitioning_scheme:   │
36)│    Hash([int_col@0], 4)   ││    Hash([int_col@0], 4)   │
37)└─────────────┬─────────────┘└─────────────┬─────────────┘
38)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
39)│      RepartitionExec      ││      RepartitionExec      │
40)│    --------------------   ││    --------------------   │
41)│  output_partition_count:  ││  output_partition_count:  │
42)│             1             ││             1             │
43)│                           ││                           │
44)│    partitioning_scheme:   ││    partitioning_scheme:   │
45)│     RoundRobinBatch(4)    ││     RoundRobinBatch(4)    │
46)└─────────────┬─────────────┘└─────────────┬─────────────┘
47)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
48)│       DataSourceExec      ││       DataSourceExec      │
49)│    --------------------   ││    --------------------   │
50)│          files: 1         ││          files: 1         │
51)│        format: csv        ││      format: parquet      │
52)└───────────────────────────┘└───────────────────────────┘

# Long Filter (demonstrate what happens with wrapping)
query TT
explain SELECT int_col FROM table1
WHERE string_col != 'foo' AND string_col != 'bar' AND string_col != 'a really long string constant'
;
----
physical_plan
01)┌───────────────────────────┐
02)│    CoalesceBatchesExec    │
03)└─────────────┬─────────────┘
04)┌─────────────┴─────────────┐
05)│         FilterExec        │
06)│    --------------------   │
07)│         predicate:        │
08)│  string_col@1 != foo AND  │
09)│     string_col@1 != bar   │
10)│    AND string_col@1 != a  │
11)│     really long string    │
12)│          constant         │
13)└─────────────┬─────────────┘
14)┌─────────────┴─────────────┐
15)│      RepartitionExec      │
16)│    --------------------   │
17)│  output_partition_count:  │
18)│             1             │
19)│                           │
20)│    partitioning_scheme:   │
21)│     RoundRobinBatch(4)    │
22)└─────────────┬─────────────┘
23)┌─────────────┴─────────────┐
24)│       DataSourceExec      │
25)│    --------------------   │
26)│          files: 1         │
27)│        format: csv        │
28)└───────────────────────────┘

# Check maximum line limit.
query TT
explain SELECT int_col FROM table1
WHERE string_col != 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa';
----
physical_plan
01)┌───────────────────────────┐
02)│    CoalesceBatchesExec    │
03)└─────────────┬─────────────┘
04)┌─────────────┴─────────────┐
05)│         FilterExec        │
06)│    --------------------   │
07)│         predicate:        │
08)│      string_col@1 !=      │
09)│       aaaaaaaaaaaaaa      │
10)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
11)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
12)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
13)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
14)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
15)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
16)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
17)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
18)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
19)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
20)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
21)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
22)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
23)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
24)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
25)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
26)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
27)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
28)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
29)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
30)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
31)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
32)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
33)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
34)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
35)│aaaaaaaaaaaaaaaaaaaaaaaaaaa│
36)│            ...            │
37)└─────────────┬─────────────┘
38)┌─────────────┴─────────────┐
39)│      RepartitionExec      │
40)│    --------------------   │
41)│  output_partition_count:  │
42)│             1             │
43)│                           │
44)│    partitioning_scheme:   │
45)│     RoundRobinBatch(4)    │
46)└─────────────┬─────────────┘
47)┌─────────────┴─────────────┐
48)│       DataSourceExec      │
49)│    --------------------   │
50)│          files: 1         │
51)│        format: csv        │
52)└───────────────────────────┘

# Check exactly the render width.
query TT
explain SELECT int_col FROM table1
WHERE string_col != 'aaaaaaaaaaa';
----
physical_plan
01)┌───────────────────────────┐
02)│    CoalesceBatchesExec    │
03)└─────────────┬─────────────┘
04)┌─────────────┴─────────────┐
05)│         FilterExec        │
06)│    --------------------   │
07)│         predicate:        │
08)│string_col@1 != aaaaaaaaaaa│
09)└─────────────┬─────────────┘
10)┌─────────────┴─────────────┐
11)│      RepartitionExec      │
12)│    --------------------   │
13)│  output_partition_count:  │
14)│             1             │
15)│                           │
16)│    partitioning_scheme:   │
17)│     RoundRobinBatch(4)    │
18)└─────────────┬─────────────┘
19)┌─────────────┴─────────────┐
20)│       DataSourceExec      │
21)│    --------------------   │
22)│          files: 1         │
23)│        format: csv        │
24)└───────────────────────────┘

# Check with the render witdth + 1.
query TT
explain SELECT int_col FROM table1
WHERE string_col != 'aaaaaaaaaaaa';
----
physical_plan
01)┌───────────────────────────┐
02)│    CoalesceBatchesExec    │
03)└─────────────┬─────────────┘
04)┌─────────────┴─────────────┐
05)│         FilterExec        │
06)│    --------------------   │
07)│         predicate:        │
08)│      string_col@1 !=      │
09)│        aaaaaaaaaaaa       │
10)└─────────────┬─────────────┘
11)┌─────────────┴─────────────┐
12)│      RepartitionExec      │
13)│    --------------------   │
14)│  output_partition_count:  │
15)│             1             │
16)│                           │
17)│    partitioning_scheme:   │
18)│     RoundRobinBatch(4)    │
19)└─────────────┬─────────────┘
20)┌─────────────┴─────────────┐
21)│       DataSourceExec      │
22)│    --------------------   │
23)│          files: 1         │
24)│        format: csv        │
25)└───────────────────────────┘

# Query with filter on csv
query TT
explain SELECT int_col FROM table1 WHERE string_col != 'foo';
----
physical_plan
01)┌───────────────────────────┐
02)│    CoalesceBatchesExec    │
03)└─────────────┬─────────────┘
04)┌─────────────┴─────────────┐
05)│         FilterExec        │
06)│    --------------------   │
07)│         predicate:        │
08)│    string_col@1 != foo    │
09)└─────────────┬─────────────┘
10)┌─────────────┴─────────────┐
11)│      RepartitionExec      │
12)│    --------------------   │
13)│  output_partition_count:  │
14)│             1             │
15)│                           │
16)│    partitioning_scheme:   │
17)│     RoundRobinBatch(4)    │
18)└─────────────┬─────────────┘
19)┌─────────────┴─────────────┐
20)│       DataSourceExec      │
21)│    --------------------   │
22)│          files: 1         │
23)│        format: csv        │
24)└───────────────────────────┘


# Query with filter on parquet
query TT
explain SELECT int_col FROM table2 WHERE string_col != 'foo';
----
physical_plan
01)┌───────────────────────────┐
02)│    CoalesceBatchesExec    │
03)└─────────────┬─────────────┘
04)┌─────────────┴─────────────┐
05)│         FilterExec        │
06)│    --------------------   │
07)│         predicate:        │
08)│    string_col@1 != foo    │
09)└─────────────┬─────────────┘
10)┌─────────────┴─────────────┐
11)│      RepartitionExec      │
12)│    --------------------   │
13)│  output_partition_count:  │
14)│             1             │
15)│                           │
16)│    partitioning_scheme:   │
17)│     RoundRobinBatch(4)    │
18)└─────────────┬─────────────┘
19)┌─────────────┴─────────────┐
20)│       DataSourceExec      │
21)│    --------------------   │
22)│          files: 1         │
23)│      format: parquet      │
24)│                           │
25)│         predicate:        │
26)│    string_col@1 != foo    │
27)└───────────────────────────┘

# Query with filter on memory
query TT
explain SELECT int_col FROM table3 WHERE string_col != 'foo';
----
physical_plan
01)┌───────────────────────────┐
02)│    CoalesceBatchesExec    │
03)└─────────────┬─────────────┘
04)┌─────────────┴─────────────┐
05)│         FilterExec        │
06)│    --------------------   │
07)│         predicate:        │
08)│    string_col@1 != foo    │
09)└─────────────┬─────────────┘
10)┌─────────────┴─────────────┐
11)│       DataSourceExec      │
12)│    --------------------   │
13)│        bytes: 1560        │
14)│       format: memory      │
15)│          rows: 1          │
16)└───────────────────────────┘

# Query with filter on json
query TT
explain SELECT int_col FROM table4 WHERE string_col != 'foo';
----
physical_plan
01)┌───────────────────────────┐
02)│    CoalesceBatchesExec    │
03)└─────────────┬─────────────┘
04)┌─────────────┴─────────────┐
05)│         FilterExec        │
06)│    --------------------   │
07)│         predicate:        │
08)│    string_col@1 != foo    │
09)└─────────────┬─────────────┘
10)┌─────────────┴─────────────┐
11)│      RepartitionExec      │
12)│    --------------------   │
13)│  output_partition_count:  │
14)│             1             │
15)│                           │
16)│    partitioning_scheme:   │
17)│     RoundRobinBatch(4)    │
18)└─────────────┬─────────────┘
19)┌─────────────┴─────────────┐
20)│       DataSourceExec      │
21)│    --------------------   │
22)│          files: 1         │
23)│        format: json       │
24)└───────────────────────────┘

# Query with filter on arrow
query TT
explain SELECT int_col FROM table5 WHERE string_col != 'foo';
----
physical_plan
01)┌───────────────────────────┐
02)│    CoalesceBatchesExec    │
03)└─────────────┬─────────────┘
04)┌─────────────┴─────────────┐
05)│         FilterExec        │
06)│    --------------------   │
07)│         predicate:        │
08)│    string_col@1 != foo    │
09)└─────────────┬─────────────┘
10)┌─────────────┴─────────────┐
11)│      RepartitionExec      │
12)│    --------------------   │
13)│  output_partition_count:  │
14)│             1             │
15)│                           │
16)│    partitioning_scheme:   │
17)│     RoundRobinBatch(4)    │
18)└─────────────┬─────────────┘
19)┌─────────────┴─────────────┐
20)│       DataSourceExec      │
21)│    --------------------   │
22)│          files: 1         │
23)│       format: arrow       │
24)└───────────────────────────┘


# Query with window agg.
query TT
explain select count(*) over() from table1;
----
physical_plan
01)┌───────────────────────────┐
02)│       ProjectionExec      │
03)│    --------------------   │
04)│   count(*) ROWS BETWEEN   │
05)│     UNBOUNDED PRECEDING   │
06)│  AND UNBOUNDED FOLLOWING: │
07)│    count(Int64(1)) ROWS   │
08)│      BETWEEN UNBOUNDED    │
09)│   PRECEDING AND UNBOUNDED │
10)│         FOLLOWING@0       │
11)└─────────────┬─────────────┘
12)┌─────────────┴─────────────┐
13)│       WindowAggExec       │
14)│    --------------------   │
15)│        select_list:       │
16)│    count(Int64(1)) ROWS   │
17)│      BETWEEN UNBOUNDED    │
18)│   PRECEDING AND UNBOUNDED │
19)│          FOLLOWING        │
20)└─────────────┬─────────────┘
21)┌─────────────┴─────────────┐
22)│       DataSourceExec      │
23)│    --------------------   │
24)│          files: 1         │
25)│        format: csv        │
26)└───────────────────────────┘

# Query with bounded window agg.
query TT
explain SELECT
    v1,
    SUM(v1) OVER (ORDER BY v1 ROWS BETWEEN 1 PRECEDING AND CURRENT ROW) AS rolling_sum
FROM generate_series(1, 1000) AS t1(v1);
----
physical_plan
01)┌───────────────────────────┐
02)│       ProjectionExec      │
03)│    --------------------   │
04)│        rolling_sum:       │
05)│ sum(t1.v1) ORDER BY [t1.v1│
06)│    ASC NULLS LAST] ROWS   │
07)│     BETWEEN 1 PRECEDING   │
08)│      AND CURRENT ROW@1    │
09)│                           │
10)│          v1: v1@0         │
11)└─────────────┬─────────────┘
12)┌─────────────┴─────────────┐
13)│    BoundedWindowAggExec   │
14)│    --------------------   │
15)│        mode: Sorted       │
16)│                           │
17)│        select_list:       │
18)│ sum(t1.v1) ORDER BY [t1.v1│
19)│    ASC NULLS LAST] ROWS   │
20)│     BETWEEN 1 PRECEDING   │
21)│       AND CURRENT ROW     │
22)└─────────────┬─────────────┘
23)┌─────────────┴─────────────┐
24)│          SortExec         │
25)│    --------------------   │
26)│    v1@0 ASC NULLS LAST    │
27)└─────────────┬─────────────┘
28)┌─────────────┴─────────────┐
29)│       ProjectionExec      │
30)│    --------------------   │
31)│        v1: value@0        │
32)└─────────────┬─────────────┘
33)┌─────────────┴─────────────┐
34)│       LazyMemoryExec      │
35)└───────────────────────────┘

query TT
explain select 
  count(*) over(),
  row_number() over ()
from table1
----
physical_plan
01)┌───────────────────────────┐
02)│       ProjectionExec      │
03)│    --------------------   │
04)│   count(*) ROWS BETWEEN   │
05)│     UNBOUNDED PRECEDING   │
06)│  AND UNBOUNDED FOLLOWING: │
07)│    count(Int64(1)) ROWS   │
08)│      BETWEEN UNBOUNDED    │
09)│   PRECEDING AND UNBOUNDED │
10)│         FOLLOWING@0       │
11)│                           │
12)│ row_number() ROWS BETWEEN │
13)│   UNBOUNDED PRECEDING AND │
14)│    UNBOUNDED FOLLOWING:   │
15)│ row_number() ROWS BETWEEN │
16)│   UNBOUNDED PRECEDING AND │
17)│    UNBOUNDED FOLLOWING@1  │
18)└─────────────┬─────────────┘
19)┌─────────────┴─────────────┐
20)│       WindowAggExec       │
21)│    --------------------   │
22)│        select_list:       │
23)│    count(Int64(1)) ROWS   │
24)│      BETWEEN UNBOUNDED    │
25)│   PRECEDING AND UNBOUNDED │
26)│   FOLLOWING, row_number() │
27)│   ROWS BETWEEN UNBOUNDED  │
28)│   PRECEDING AND UNBOUNDED │
29)│          FOLLOWING        │
30)└─────────────┬─────────────┘
31)┌─────────────┴─────────────┐
32)│       DataSourceExec      │
33)│    --------------------   │
34)│          files: 1         │
35)│        format: csv        │
36)└───────────────────────────┘

# Query for sort.
query TT
explain SELECT * FROM table1 ORDER BY string_col;
----
physical_plan
01)┌───────────────────────────┐
02)│          SortExec         │
03)│    --------------------   │
04)│string_col@1 ASC NULLS LAST│
05)└─────────────┬─────────────┘
06)┌─────────────┴─────────────┐
07)│       DataSourceExec      │
08)│    --------------------   │
09)│          files: 1         │
10)│        format: csv        │
11)└───────────────────────────┘

# Query for sort with limit.
query TT
explain SELECT * FROM table1 ORDER BY string_col LIMIT 1;
----
physical_plan
01)┌───────────────────────────┐
02)│          SortExec         │
03)│    --------------------   │
04)│          limit: 1         │
05)│                           │
06)│string_col@1 ASC NULLS LAST│
07)└─────────────┬─────────────┘
08)┌─────────────┴─────────────┐
09)│       DataSourceExec      │
10)│    --------------------   │
11)│          files: 1         │
12)│        format: csv        │
13)└───────────────────────────┘

# Query with projection on csv
query TT
explain SELECT int_col, bigint_col, int_col+bigint_col AS sum_col FROM table1;
----
physical_plan
01)┌───────────────────────────┐
02)│       ProjectionExec      │
03)│    --------------------   │
04)│        bigint_col:        │
05)│        bigint_col@1       │
06)│                           │
07)│     int_col: int_col@0    │
08)│                           │
09)│          sum_col:         │
10)│ CAST(int_col@0 AS Int64) +│
11)│        bigint_col@1       │
12)└─────────────┬─────────────┘
13)┌─────────────┴─────────────┐
14)│      RepartitionExec      │
15)│    --------------------   │
16)│  output_partition_count:  │
17)│             1             │
18)│                           │
19)│    partitioning_scheme:   │
20)│     RoundRobinBatch(4)    │
21)└─────────────┬─────────────┘
22)┌─────────────┴─────────────┐
23)│       DataSourceExec      │
24)│    --------------------   │
25)│          files: 1         │
26)│        format: csv        │
27)└───────────────────────────┘

query TT
explain select 
  rank() over(ORDER BY int_col DESC),
  row_number() over (ORDER BY int_col ASC)
from table1
----
physical_plan
01)┌───────────────────────────┐
02)│       ProjectionExec      │
03)│    --------------------   │
04)│  rank() ORDER BY [table1  │
05)│    .int_col DESC NULLS    │
06)│    FIRST] RANGE BETWEEN   │
07)│   UNBOUNDED PRECEDING AND │
08)│        CURRENT ROW:       │
09)│  rank() ORDER BY [table1  │
10)│    .int_col DESC NULLS    │
11)│    FIRST] RANGE BETWEEN   │
12)│   UNBOUNDED PRECEDING AND │
13)│        CURRENT ROW@1      │
14)│                           │
15)│   row_number() ORDER BY   │
16)│    [table1.int_col ASC    │
17)│      NULLS LAST] RANGE    │
18)│      BETWEEN UNBOUNDED    │
19)│    PRECEDING AND CURRENT  │
20)│            ROW:           │
21)│   row_number() ORDER BY   │
22)│    [table1.int_col ASC    │
23)│      NULLS LAST] RANGE    │
24)│      BETWEEN UNBOUNDED    │
25)│    PRECEDING AND CURRENT  │
26)│            ROW@2          │
27)└─────────────┬─────────────┘
28)┌─────────────┴─────────────┐
29)│    BoundedWindowAggExec   │
30)│    --------------------   │
31)│        mode: Sorted       │
32)│                           │
33)│        select_list:       │
34)│   row_number() ORDER BY   │
35)│    [table1.int_col ASC    │
36)│      NULLS LAST] RANGE    │
37)│      BETWEEN UNBOUNDED    │
38)│    PRECEDING AND CURRENT  │
39)│             ROW           │
40)└─────────────┬─────────────┘
41)┌─────────────┴─────────────┐
42)│          SortExec         │
43)│    --------------------   │
44)│  int_col@0 ASC NULLS LAST │
45)└─────────────┬─────────────┘
46)┌─────────────┴─────────────┐
47)│    BoundedWindowAggExec   │
48)│    --------------------   │
49)│        mode: Sorted       │
50)│                           │
51)│        select_list:       │
52)│  rank() ORDER BY [table1  │
53)│    .int_col DESC NULLS    │
54)│    FIRST] RANGE BETWEEN   │
55)│   UNBOUNDED PRECEDING AND │
56)│         CURRENT ROW       │
57)└─────────────┬─────────────┘
58)┌─────────────┴─────────────┐
59)│          SortExec         │
60)│    --------------------   │
61)│       int_col@0 DESC      │
62)└─────────────┬─────────────┘
63)┌─────────────┴─────────────┐
64)│       DataSourceExec      │
65)│    --------------------   │
66)│          files: 1         │
67)│        format: csv        │
68)└───────────────────────────┘

# Query with projection on parquet
query TT
explain SELECT int_col, bigint_col, int_col+bigint_col AS sum_col FROM table2;
----
physical_plan
01)┌───────────────────────────┐
02)│       ProjectionExec      │
03)│    --------------------   │
04)│        bigint_col:        │
05)│        bigint_col@1       │
06)│                           │
07)│     int_col: int_col@0    │
08)│                           │
09)│          sum_col:         │
10)│ CAST(int_col@0 AS Int64) +│
11)│        bigint_col@1       │
12)└─────────────┬─────────────┘
13)┌─────────────┴─────────────┐
14)│      RepartitionExec      │
15)│    --------------------   │
16)│  output_partition_count:  │
17)│             1             │
18)│                           │
19)│    partitioning_scheme:   │
20)│     RoundRobinBatch(4)    │
21)└─────────────┬─────────────┘
22)┌─────────────┴─────────────┐
23)│       DataSourceExec      │
24)│    --------------------   │
25)│          files: 1         │
26)│      format: parquet      │
27)└───────────────────────────┘


# Query with projection on memory
query TT
explain SELECT int_col, bigint_col, int_col+bigint_col AS sum_col FROM table3;
----
physical_plan
01)┌───────────────────────────┐
02)│       ProjectionExec      │
03)│    --------------------   │
04)│        bigint_col:        │
05)│        bigint_col@1       │
06)│                           │
07)│     int_col: int_col@0    │
08)│                           │
09)│          sum_col:         │
10)│ CAST(int_col@0 AS Int64) +│
11)│        bigint_col@1       │
12)└─────────────┬─────────────┘
13)┌─────────────┴─────────────┐
14)│       DataSourceExec      │
15)│    --------------------   │
16)│        bytes: 1560        │
17)│       format: memory      │
18)│          rows: 1          │
19)└───────────────────────────┘

# Query with projection on json
query TT
explain SELECT int_col, bigint_col, int_col+bigint_col AS sum_col FROM table4;
----
physical_plan
01)┌───────────────────────────┐
02)│       ProjectionExec      │
03)│    --------------------   │
04)│        bigint_col:        │
05)│        bigint_col@0       │
06)│                           │
07)│     int_col: int_col@1    │
08)│                           │
09)│          sum_col:         │
10)│  int_col@1 + bigint_col@0 │
11)└─────────────┬─────────────┘
12)┌─────────────┴─────────────┐
13)│      RepartitionExec      │
14)│    --------------------   │
15)│  output_partition_count:  │
16)│             1             │
17)│                           │
18)│    partitioning_scheme:   │
19)│     RoundRobinBatch(4)    │
20)└─────────────┬─────────────┘
21)┌─────────────┴─────────────┐
22)│       DataSourceExec      │
23)│    --------------------   │
24)│          files: 1         │
25)│        format: json       │
26)└───────────────────────────┘


# Query with projection on arrow
query TT
explain SELECT int_col, bigint_col, int_col+bigint_col AS sum_col FROM table5;
----
physical_plan
01)┌───────────────────────────┐
02)│       ProjectionExec      │
03)│    --------------------   │
04)│        bigint_col:        │
05)│        bigint_col@1       │
06)│                           │
07)│     int_col: int_col@0    │
08)│                           │
09)│          sum_col:         │
10)│ CAST(int_col@0 AS Int64) +│
11)│        bigint_col@1       │
12)└─────────────┬─────────────┘
13)┌─────────────┴─────────────┐
14)│      RepartitionExec      │
15)│    --------------------   │
16)│  output_partition_count:  │
17)│             1             │
18)│                           │
19)│    partitioning_scheme:   │
20)│     RoundRobinBatch(4)    │
21)└─────────────┬─────────────┘
22)┌─────────────┴─────────────┐
23)│       DataSourceExec      │
24)│    --------------------   │
25)│          files: 1         │
26)│       format: arrow       │
27)└───────────────────────────┘

# Query with PartialSortExec.
query TT
EXPLAIN SELECT *
FROM annotated_data_infinite2
ORDER BY a, b, d;
----
physical_plan
01)┌───────────────────────────┐
02)│      PartialSortExec      │
03)│    --------------------   │
04)│  a@1 ASC NULLS LAST, b@2  │
05)│     ASC NULLS LAST, d@4   │
06)│       ASC NULLS LAST      │
07)└─────────────┬─────────────┘
08)┌─────────────┴─────────────┐
09)│     StreamingTableExec    │
10)│    --------------------   │
11)│       infinite: true      │
12)│        limit: None        │
13)└───────────────────────────┘

query TT
EXPLAIN SELECT *
FROM annotated_data_infinite2
ORDER BY a, b, d
LIMIT 50;
----
physical_plan
01)┌───────────────────────────┐
02)│      PartialSortExec      │
03)│    --------------------   │
04)│  a@1 ASC NULLS LAST, b@2  │
05)│     ASC NULLS LAST, d@4   │
06)│       ASC NULLS LAST      │
07)│                           │
08)│         limit: 50         │
09)└─────────────┬─────────────┘
10)┌─────────────┴─────────────┐
11)│     StreamingTableExec    │
12)│    --------------------   │
13)│       infinite: true      │
14)│        limit: None        │
15)└───────────────────────────┘

# Query with hash join.
query TT
explain select * from table1 inner join table2 on table1.int_col = table2.int_col and table1.string_col = table2.string_col;
----
physical_plan
01)┌───────────────────────────┐
02)│    CoalesceBatchesExec    │
03)└─────────────┬─────────────┘
04)┌─────────────┴─────────────┐
05)│        HashJoinExec       │
06)│    --------------------   │
07)│            on:            │
08)│ (int_col@0 = int_col@0),  ├──────────────┐
09)│  (CAST(table1.string_col  │              │
10)│      AS Utf8View)@4 =     │              │
11)│        string_col@1)      │              │
12)└─────────────┬─────────────┘              │
13)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
14)│    CoalesceBatchesExec    ││    CoalesceBatchesExec    │
15)└─────────────┬─────────────┘└─────────────┬─────────────┘
16)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
17)│      RepartitionExec      ││      RepartitionExec      │
18)│    --------------------   ││    --------------------   │
19)│  output_partition_count:  ││  output_partition_count:  │
20)│             4             ││             4             │
21)│                           ││                           │
22)│    partitioning_scheme:   ││    partitioning_scheme:   │
23)│   Hash([int_col@0, CAST   ││      Hash([int_col@0,     │
24)│     (table1.string_col    ││       string_col@1],      │
25)│     AS Utf8View)@4], 4)   ││             4)            │
26)└─────────────┬─────────────┘└─────────────┬─────────────┘
27)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
28)│       ProjectionExec      ││      RepartitionExec      │
29)│    --------------------   ││    --------------------   │
30)│ CAST(table1.string_col AS ││  output_partition_count:  │
31)│         Utf8View):        ││             1             │
32)│    CAST(string_col@1 AS   ││                           │
33)│          Utf8View)        ││    partitioning_scheme:   │
34)│                           ││     RoundRobinBatch(4)    │
35)│        bigint_col:        ││                           │
36)│        bigint_col@2       ││                           │
37)│                           ││                           │
38)│    date_col: date_col@3   ││                           │
39)│     int_col: int_col@0    ││                           │
40)│                           ││                           │
41)│        string_col:        ││                           │
42)│        string_col@1       ││                           │
43)└─────────────┬─────────────┘└─────────────┬─────────────┘
44)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
45)│      RepartitionExec      ││       DataSourceExec      │
46)│    --------------------   ││    --------------------   │
47)│  output_partition_count:  ││          files: 1         │
48)│             1             ││      format: parquet      │
49)│                           ││                           │
50)│    partitioning_scheme:   ││                           │
51)│     RoundRobinBatch(4)    ││                           │
52)└─────────────┬─────────────┘└───────────────────────────┘
53)┌─────────────┴─────────────┐
54)│       DataSourceExec      │
55)│    --------------------   │
56)│          files: 1         │
57)│        format: csv        │
58)└───────────────────────────┘

# Query with outer hash join.
query TT
explain select * from table1 left outer join table2 on table1.int_col = table2.int_col and table1.string_col = table2.string_col;
----
physical_plan
01)┌───────────────────────────┐
02)│    CoalesceBatchesExec    │
03)└─────────────┬─────────────┘
04)┌─────────────┴─────────────┐
05)│        HashJoinExec       │
06)│    --------------------   │
07)│      join_type: Left      │
08)│                           │
09)│            on:            ├──────────────┐
10)│ (int_col@0 = int_col@0),  │              │
11)│  (CAST(table1.string_col  │              │
12)│      AS Utf8View)@4 =     │              │
13)│        string_col@1)      │              │
14)└─────────────┬─────────────┘              │
15)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
16)│    CoalesceBatchesExec    ││    CoalesceBatchesExec    │
17)└─────────────┬─────────────┘└─────────────┬─────────────┘
18)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
19)│      RepartitionExec      ││      RepartitionExec      │
20)│    --------------------   ││    --------------------   │
21)│  output_partition_count:  ││  output_partition_count:  │
22)│             4             ││             4             │
23)│                           ││                           │
24)│    partitioning_scheme:   ││    partitioning_scheme:   │
25)│   Hash([int_col@0, CAST   ││      Hash([int_col@0,     │
26)│     (table1.string_col    ││       string_col@1],      │
27)│     AS Utf8View)@4], 4)   ││             4)            │
28)└─────────────┬─────────────┘└─────────────┬─────────────┘
29)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
30)│       ProjectionExec      ││      RepartitionExec      │
31)│    --------------------   ││    --------------------   │
32)│ CAST(table1.string_col AS ││  output_partition_count:  │
33)│         Utf8View):        ││             1             │
34)│    CAST(string_col@1 AS   ││                           │
35)│          Utf8View)        ││    partitioning_scheme:   │
36)│                           ││     RoundRobinBatch(4)    │
37)│        bigint_col:        ││                           │
38)│        bigint_col@2       ││                           │
39)│                           ││                           │
40)│    date_col: date_col@3   ││                           │
41)│     int_col: int_col@0    ││                           │
42)│                           ││                           │
43)│        string_col:        ││                           │
44)│        string_col@1       ││                           │
45)└─────────────┬─────────────┘└─────────────┬─────────────┘
46)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
47)│      RepartitionExec      ││       DataSourceExec      │
48)│    --------------------   ││    --------------------   │
49)│  output_partition_count:  ││          files: 1         │
50)│             1             ││      format: parquet      │
51)│                           ││                           │
52)│    partitioning_scheme:   ││                           │
53)│     RoundRobinBatch(4)    ││                           │
54)└─────────────┬─────────────┘└───────────────────────────┘
55)┌─────────────┴─────────────┐
56)│       DataSourceExec      │
57)│    --------------------   │
58)│          files: 1         │
59)│        format: csv        │
60)└───────────────────────────┘

# Query with nested loop join.
query TT
explain select int_col from table1 where exists (select count(*) from table2);
----
physical_plan
01)┌───────────────────────────┐
02)│     NestedLoopJoinExec    │
03)│    --------------------   ├──────────────┐
04)│    join_type: LeftSemi    │              │
05)└─────────────┬─────────────┘              │
06)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
07)│       DataSourceExec      ││       ProjectionExec      │
08)│    --------------------   ││                           │
09)│          files: 1         ││                           │
10)│        format: csv        ││                           │
11)└───────────────────────────┘└─────────────┬─────────────┘
12)-----------------------------┌─────────────┴─────────────┐
13)-----------------------------│       AggregateExec       │
14)-----------------------------│    --------------------   │
15)-----------------------------│   aggr: count(Int64(1))   │
16)-----------------------------│        mode: Final        │
17)-----------------------------└─────────────┬─────────────┘
18)-----------------------------┌─────────────┴─────────────┐
19)-----------------------------│   CoalescePartitionsExec  │
20)-----------------------------└─────────────┬─────────────┘
21)-----------------------------┌─────────────┴─────────────┐
22)-----------------------------│       AggregateExec       │
23)-----------------------------│    --------------------   │
24)-----------------------------│   aggr: count(Int64(1))   │
25)-----------------------------│       mode: Partial       │
26)-----------------------------└─────────────┬─────────────┘
27)-----------------------------┌─────────────┴─────────────┐
28)-----------------------------│      RepartitionExec      │
29)-----------------------------│    --------------------   │
30)-----------------------------│  output_partition_count:  │
31)-----------------------------│             1             │
32)-----------------------------│                           │
33)-----------------------------│    partitioning_scheme:   │
34)-----------------------------│     RoundRobinBatch(4)    │
35)-----------------------------└─────────────┬─────────────┘
36)-----------------------------┌─────────────┴─────────────┐
37)-----------------------------│       DataSourceExec      │
38)-----------------------------│    --------------------   │
39)-----------------------------│          files: 1         │
40)-----------------------------│      format: parquet      │
41)-----------------------------└───────────────────────────┘

# Query with cross join.
query TT
explain select * from table1 cross join table2 ;
----
physical_plan
01)┌───────────────────────────┐
02)│       CrossJoinExec       ├──────────────┐
03)└─────────────┬─────────────┘              │
04)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
05)│       DataSourceExec      ││      RepartitionExec      │
06)│    --------------------   ││    --------------------   │
07)│          files: 1         ││  output_partition_count:  │
08)│        format: csv        ││             1             │
09)│                           ││                           │
10)│                           ││    partitioning_scheme:   │
11)│                           ││     RoundRobinBatch(4)    │
12)└───────────────────────────┘└─────────────┬─────────────┘
13)-----------------------------┌─────────────┴─────────────┐
14)-----------------------------│       DataSourceExec      │
15)-----------------------------│    --------------------   │
16)-----------------------------│          files: 1         │
17)-----------------------------│      format: parquet      │
18)-----------------------------└───────────────────────────┘


# Query with sort merge join.
statement ok
set datafusion.optimizer.prefer_hash_join = false;

query TT
explain select * from hashjoin_datatype_table_t1 t1 join hashjoin_datatype_table_t2 t2 on t1.c1 = t2.c1
----
physical_plan
01)┌───────────────────────────┐
02)│     SortMergeJoinExec     │
03)│    --------------------   ├──────────────┐
04)│     on: (c1@0 = c1@0)     │              │
05)└─────────────┬─────────────┘              │
06)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
07)│          SortExec         ││          SortExec         │
08)│    --------------------   ││    --------------------   │
09)│          c1@0 ASC         ││          c1@0 ASC         │
10)└─────────────┬─────────────┘└─────────────┬─────────────┘
11)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
12)│       DataSourceExec      ││       DataSourceExec      │
13)│    --------------------   ││    --------------------   │
14)│        bytes: 6040        ││        bytes: 6040        │
15)│       format: memory      ││       format: memory      │
16)│          rows: 1          ││          rows: 1          │
17)└───────────────────────────┘└───────────────────────────┘

statement ok
set datafusion.optimizer.prefer_hash_join = true;

# cleanup
statement ok
drop table table1;

statement ok
drop table table2;

statement ok
drop table table3;

statement ok
drop table table4;

statement ok
drop table table5;

# Test on StreamingTableExec
# prepare table
statement ok
CREATE UNBOUNDED EXTERNAL TABLE data (
    "date"   DATE, 
    "ticker" VARCHAR, 
    "time"   TIMESTAMP,
) STORED AS CSV
WITH ORDER ("date", "ticker", "time")
LOCATION './a.parquet';


# query
query TT
explain SELECT * FROM data 
WHERE ticker = 'A' 
ORDER BY "date", "time";
----
physical_plan
01)┌───────────────────────────┐
02)│  SortPreservingMergeExec  │
03)│    --------------------   │
04)│   date@0 ASC NULLS LAST,  │
05)│    time@2 ASC NULLS LAST  │
06)└─────────────┬─────────────┘
07)┌─────────────┴─────────────┐
08)│    CoalesceBatchesExec    │
09)└─────────────┬─────────────┘
10)┌─────────────┴─────────────┐
11)│         FilterExec        │
12)│    --------------------   │
13)│         predicate:        │
14)│        ticker@1 = A       │
15)└─────────────┬─────────────┘
16)┌─────────────┴─────────────┐
17)│      RepartitionExec      │
18)│    --------------------   │
19)│  output_partition_count:  │
20)│             1             │
21)│                           │
22)│    partitioning_scheme:   │
23)│     RoundRobinBatch(4)    │
24)└─────────────┬─────────────┘
25)┌─────────────┴─────────────┐
26)│     StreamingTableExec    │
27)│    --------------------   │
28)│       infinite: true      │
29)│        limit: None        │
30)└───────────────────────────┘


# constant ticker, CAST(time AS DATE) = time, order by time
query TT
explain SELECT * FROM data
WHERE ticker = 'A' AND CAST(time AS DATE) = date
ORDER BY "time"
----
physical_plan
01)┌───────────────────────────┐
02)│  SortPreservingMergeExec  │
03)│    --------------------   │
04)│   time@2 ASC NULLS LAST   │
05)└─────────────┬─────────────┘
06)┌─────────────┴─────────────┐
07)│    CoalesceBatchesExec    │
08)└─────────────┬─────────────┘
09)┌─────────────┴─────────────┐
10)│         FilterExec        │
11)│    --------------------   │
12)│         predicate:        │
13)│ ticker@1 = A AND CAST(time│
14)│   @2 AS Date32) = date@0  │
15)└─────────────┬─────────────┘
16)┌─────────────┴─────────────┐
17)│      RepartitionExec      │
18)│    --------------------   │
19)│  output_partition_count:  │
20)│             1             │
21)│                           │
22)│    partitioning_scheme:   │
23)│     RoundRobinBatch(4)    │
24)└─────────────┬─────────────┘
25)┌─────────────┴─────────────┐
26)│     StreamingTableExec    │
27)│    --------------------   │
28)│       infinite: true      │
29)│        limit: None        │
30)└───────────────────────────┘

# same thing but order by date
query TT
explain SELECT * FROM data
WHERE ticker = 'A' AND CAST(time AS DATE) = date
ORDER BY "date"
----
physical_plan
01)┌───────────────────────────┐
02)│  SortPreservingMergeExec  │
03)│    --------------------   │
04)│   date@0 ASC NULLS LAST   │
05)└─────────────┬─────────────┘
06)┌─────────────┴─────────────┐
07)│    CoalesceBatchesExec    │
08)└─────────────┬─────────────┘
09)┌─────────────┴─────────────┐
10)│         FilterExec        │
11)│    --------------------   │
12)│         predicate:        │
13)│ ticker@1 = A AND CAST(time│
14)│   @2 AS Date32) = date@0  │
15)└─────────────┬─────────────┘
16)┌─────────────┴─────────────┐
17)│      RepartitionExec      │
18)│    --------------------   │
19)│  output_partition_count:  │
20)│             1             │
21)│                           │
22)│    partitioning_scheme:   │
23)│     RoundRobinBatch(4)    │
24)└─────────────┬─────────────┘
25)┌─────────────┴─────────────┐
26)│     StreamingTableExec    │
27)│    --------------------   │
28)│       infinite: true      │
29)│        limit: None        │
30)└───────────────────────────┘

# same thing but order by ticker
query TT
explain SELECT * FROM data
WHERE ticker = 'A' AND CAST(time AS DATE) = date
ORDER BY "ticker"
----
physical_plan
01)┌───────────────────────────┐
02)│   CoalescePartitionsExec  │
03)└─────────────┬─────────────┘
04)┌─────────────┴─────────────┐
05)│    CoalesceBatchesExec    │
06)└─────────────┬─────────────┘
07)┌─────────────┴─────────────┐
08)│         FilterExec        │
09)│    --------------------   │
10)│         predicate:        │
11)│ ticker@1 = A AND CAST(time│
12)│   @2 AS Date32) = date@0  │
13)└─────────────┬─────────────┘
14)┌─────────────┴─────────────┐
15)│      RepartitionExec      │
16)│    --------------------   │
17)│  output_partition_count:  │
18)│             1             │
19)│                           │
20)│    partitioning_scheme:   │
21)│     RoundRobinBatch(4)    │
22)└─────────────┬─────────────┘
23)┌─────────────┴─────────────┐
24)│     StreamingTableExec    │
25)│    --------------------   │
26)│       infinite: true      │
27)│        limit: None        │
28)└───────────────────────────┘


# same thing but order by time, date
query TT
explain SELECT * FROM data 
WHERE ticker = 'A' AND CAST(time AS DATE) = date
ORDER BY "time", "date";
----
physical_plan
01)┌───────────────────────────┐
02)│  SortPreservingMergeExec  │
03)│    --------------------   │
04)│   time@2 ASC NULLS LAST,  │
05)│    date@0 ASC NULLS LAST  │
06)└─────────────┬─────────────┘
07)┌─────────────┴─────────────┐
08)│    CoalesceBatchesExec    │
09)└─────────────┬─────────────┘
10)┌─────────────┴─────────────┐
11)│         FilterExec        │
12)│    --------------------   │
13)│         predicate:        │
14)│ ticker@1 = A AND CAST(time│
15)│   @2 AS Date32) = date@0  │
16)└─────────────┬─────────────┘
17)┌─────────────┴─────────────┐
18)│      RepartitionExec      │
19)│    --------------------   │
20)│  output_partition_count:  │
21)│             1             │
22)│                           │
23)│    partitioning_scheme:   │
24)│     RoundRobinBatch(4)    │
25)└─────────────┬─────────────┘
26)┌─────────────┴─────────────┐
27)│     StreamingTableExec    │
28)│    --------------------   │
29)│       infinite: true      │
30)│        limit: None        │
31)└───────────────────────────┘




# query
query TT
explain SELECT * FROM data 
WHERE date = '2006-01-02' 
ORDER BY "ticker", "time";
----
physical_plan
01)┌───────────────────────────┐
02)│  SortPreservingMergeExec  │
03)│    --------------------   │
04)│  ticker@1 ASC NULLS LAST, │
05)│    time@2 ASC NULLS LAST  │
06)└─────────────┬─────────────┘
07)┌─────────────┴─────────────┐
08)│    CoalesceBatchesExec    │
09)└─────────────┬─────────────┘
10)┌─────────────┴─────────────┐
11)│         FilterExec        │
12)│    --------------------   │
13)│         predicate:        │
14)│    date@0 = 2006-01-02    │
15)└─────────────┬─────────────┘
16)┌─────────────┴─────────────┐
17)│      RepartitionExec      │
18)│    --------------------   │
19)│  output_partition_count:  │
20)│             1             │
21)│                           │
22)│    partitioning_scheme:   │
23)│     RoundRobinBatch(4)    │
24)└─────────────┬─────────────┘
25)┌─────────────┴─────────────┐
26)│     StreamingTableExec    │
27)│    --------------------   │
28)│       infinite: true      │
29)│        limit: None        │
30)└───────────────────────────┘



# Test explain tree for WorkTableExec
query TT
EXPLAIN WITH RECURSIVE nodes AS (
    SELECT 1 as id
    UNION ALL
    SELECT id + 1 as id
    FROM nodes
    WHERE id < 10
)
SELECT * FROM nodes
----
physical_plan
01)┌───────────────────────────┐
02)│     RecursiveQueryExec    ├──────────────┐
03)└─────────────┬─────────────┘              │
04)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
05)│       ProjectionExec      ││   CoalescePartitionsExec  │
06)│    --------------------   ││                           │
07)│           id: 1           ││                           │
08)└─────────────┬─────────────┘└─────────────┬─────────────┘
09)┌─────────────┴─────────────┐┌─────────────┴─────────────┐
10)│     PlaceholderRowExec    ││       ProjectionExec      │
11)│                           ││    --------------------   │
12)│                           ││        id: id@0 + 1       │
13)└───────────────────────────┘└─────────────┬─────────────┘
14)-----------------------------┌─────────────┴─────────────┐
15)-----------------------------│    CoalesceBatchesExec    │
16)-----------------------------└─────────────┬─────────────┘
17)-----------------------------┌─────────────┴─────────────┐
18)-----------------------------│         FilterExec        │
19)-----------------------------│    --------------------   │
20)-----------------------------│    predicate: id@0 < 10   │
21)-----------------------------└─────────────┬─────────────┘
22)-----------------------------┌─────────────┴─────────────┐
23)-----------------------------│      RepartitionExec      │
24)-----------------------------│    --------------------   │
25)-----------------------------│  output_partition_count:  │
26)-----------------------------│             1             │
27)-----------------------------│                           │
28)-----------------------------│    partitioning_scheme:   │
29)-----------------------------│     RoundRobinBatch(4)    │
30)-----------------------------└─────────────┬─────────────┘
31)-----------------------------┌─────────────┴─────────────┐
32)-----------------------------│       WorkTableExec       │
33)-----------------------------│    --------------------   │
34)-----------------------------│        name: nodes        │
35)-----------------------------└───────────────────────────┘

query TT
explain COPY (VALUES (1, 'foo', 1, '2023-01-01'), (2, 'bar', 2, '2023-01-02'), (3, 'baz', 3, '2023-01-03'))
TO 'test_files/scratch/explain_tree/1.json';
----
physical_plan
01)┌───────────────────────────┐
02)│        DataSinkExec       │
03)└─────────────┬─────────────┘
04)┌─────────────┴─────────────┐
05)│       DataSourceExec      │
06)│    --------------------   │
07)│        bytes: 2672        │
08)│       format: memory      │
09)│          rows: 1          │
10)└───────────────────────────┘
