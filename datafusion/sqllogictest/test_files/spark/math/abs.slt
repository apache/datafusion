# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at

#   http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

# This file was originally created by a porting script from:
#   https://github.com/lakehq/sail/tree/43b6ed8221de5c4c4adbedbb267ae1351158b43c/crates/sail-spark-connect/tests/gold_data/function
# This file is part of the implementation of the datafusion-spark function library.
# For more information, please see:
#   https://github.com/apache/datafusion/issues/15914

## Original Query: SELECT abs(-1);
## PySpark 3.5.5 Result: {'abs(-1)': 1, 'typeof(abs(-1))': 'int', 'typeof(-1)': 'int'}
query I
SELECT abs(-1::int);
----
1

statement ok
CREATE TABLE test_nullable_integer(
    c1 TINYINT,
    c2 SMALLINT,
    c3 INT,
    c4 BIGINT,
    dataset TEXT
    )
    AS VALUES
    (NULL, NULL, NULL, NULL, 'nulls'),
    (0, 0, 0, 0, 'zeros'),
    (1, 1, 1, 1, 'ones');

query I
INSERT into test_nullable_integer values(-128, -32768, -2147483648, -9223372036854775808, 'mins');
----
1

# abs: signed int minimal values
query IIII
select abs(c1), abs(c2), abs(c3), abs(c4) from test_nullable_integer where dataset = 'mins'
----
-128 -32768 -2147483648 -9223372036854775808

statement ok
drop table test_nullable_integer

statement ok
CREATE TABLE test_nullable_float(
    c1 float,
    c2 double
    ) AS VALUES
    (-1.0, -1.0),
    (1.0, 1.0),
    (NULL, NULL),
    (0., 0.),
    ('NaN'::double, 'NaN'::double);

# abs: floats
query RR rowsort
SELECT abs(c1), abs(c2) from test_nullable_float
----
0 0
1 1
1 1
NULL NULL
NaN NaN

statement ok
drop table test_nullable_float

statement ok
CREATE TABLE test_nullable_decimal(
    c1 DECIMAL(10, 2),    /* Decimal128 */
    c2 DECIMAL(38, 10),   /* Decimal128 with max precision */
    c3 DECIMAL(40, 2),    /* Decimal256 */
    c4 DECIMAL(76, 10)    /* Decimal256 with max precision */
 ) AS VALUES
    (0, 0, 0, 0),
    (NULL, NULL, NULL, NULL);

query I
INSERT into test_nullable_decimal values
    (
        -99999999.99,
        '-9999999999999999999999999999.9999999999',
        '-99999999999999999999999999999999999999.99',
        '-999999999999999999999999999999999999999999999999999999999999999999.9999999999'
    ),
    (
        99999999.99,
        '9999999999999999999999999999.9999999999',
        '99999999999999999999999999999999999999.99',
        '999999999999999999999999999999999999999999999999999999999999999999.9999999999'
    )
----
2

# abs: decimals
query RRRR rowsort
SELECT abs(c1), abs(c2), abs(c3), abs(c4) FROM test_nullable_decimal
----
0 0 0 0
99999999.99 9999999999999999999999999999.9999999999 99999999999999999999999999999999999999.99 999999999999999999999999999999999999999999999999999999999999999999.9999999999
99999999.99 9999999999999999999999999999.9999999999 99999999999999999999999999999999999999.99 999999999999999999999999999999999999999999999999999999999999999999.9999999999
NULL NULL NULL NULL


statement ok
drop table test_nullable_decimal

## Original Query: SELECT abs(INTERVAL -'1-1' YEAR TO MONTH);
## PySpark 3.5.5 Result: {"abs(INTERVAL '-1-1' YEAR TO MONTH)": 13, "typeof(abs(INTERVAL '-1-1' YEAR TO MONTH))": 'interval year to month', "typeof(INTERVAL '-1-1' YEAR TO MONTH)": 'interval year to month'}
query error DataFusion error: This feature is not implemented: Unsupported SQL type INTERVAL YEAR TO MONTH
SELECT abs(INTERVAL '-1-1' YEAR TO MONTH::interval year to month);
