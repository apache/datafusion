# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at

#   http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

# tests for copy command
statement ok
create table source_table(col1 integer, col2 varchar) as values (1, 'Foo'), (2, 'Bar');

# Copy to directory as multiple files
query IT
COPY source_table TO 'test_files/scratch/copy/table/' (format parquet, compression 'zstd(10)');
----
2

# Copy to directory as partitioned files
query IT
COPY source_table TO 'test_files/scratch/copy/partitioned_table1/' (format parquet, compression 'zstd(10)', partition_by 'col2');
----
2

# validate multiple partitioned parquet file output
statement ok
CREATE EXTERNAL TABLE validate_partitioned_parquet STORED AS PARQUET 
LOCATION 'test_files/scratch/copy/partitioned_table1/' PARTITIONED BY (col2);

query I?
select * from validate_partitioned_parquet order by col1, col2;
----
1 Foo
2 Bar

# validate partition paths were actually generated
statement ok
CREATE EXTERNAL TABLE validate_partitioned_parquet_bar STORED AS PARQUET 
LOCATION 'test_files/scratch/copy/partitioned_table1/col2=Bar';

query I
select * from validate_partitioned_parquet_bar order by col1;
----
2

# Copy to directory as partitioned files
query ITT
COPY (values (1, 'a', 'x'), (2, 'b', 'y'), (3, 'c', 'z')) TO 'test_files/scratch/copy/partitioned_table2/' 
(format parquet, compression 'zstd(10)', partition_by 'column2, column3');
----
3

# validate multiple partitioned parquet file output
statement ok
CREATE EXTERNAL TABLE validate_partitioned_parquet2 STORED AS PARQUET 
LOCATION 'test_files/scratch/copy/partitioned_table2/' PARTITIONED BY (column2, column3);

query I??
select * from validate_partitioned_parquet2 order by column1,column2,column3;
----
1 a x
2 b y
3 c z

statement ok
CREATE EXTERNAL TABLE validate_partitioned_parquet_a_x STORED AS PARQUET 
LOCATION 'test_files/scratch/copy/partitioned_table2/column2=a/column3=x';

query I
select * from validate_partitioned_parquet_a_x order by column1;
----
1

statement ok
create table test ("'test'" varchar, "'test2'" varchar, "'test3'" varchar); 

query TTT
insert into test VALUES ('a', 'x', 'aa'), ('b','y', 'bb'), ('c', 'z', 'cc')
----
3

query T
select "'test'" from test
----
a
b
c

# Note to place a single ' inside of a literal string escape by putting two ''
query TTT
copy test to 'test_files/scratch/copy/escape_quote' (format csv, partition_by '''test2'',''test3''')
----
3

statement ok
CREATE EXTERNAL TABLE validate_partitioned_escape_quote STORED AS CSV 
LOCATION 'test_files/scratch/copy/escape_quote/' PARTITIONED BY ("'test2'", "'test3'");

# This triggers a panic (index out of bounds)
# https://github.com/apache/arrow-datafusion/issues/9269
#query
#select * from validate_partitioned_escape_quote;

query TT
EXPLAIN COPY source_table TO 'test_files/scratch/copy/table/' (format parquet, compression 'zstd(10)');
----
logical_plan
CopyTo: format=parquet output_url=test_files/scratch/copy/table/ options: (compression 'zstd(10)')
--TableScan: source_table projection=[col1, col2]
physical_plan
FileSinkExec: sink=ParquetSink(file_groups=[])
--MemoryExec: partitions=1, partition_sizes=[1]

# Error case
query error DataFusion error: Invalid or Unsupported Configuration: Format not explicitly set and unable to get file extension!
EXPLAIN COPY source_table to 'test_files/scratch/copy/table/'

query error DataFusion error: SQL error: ParserError\("Expected end of statement, found: query"\)
EXPLAIN COPY source_table to 'test_files/scratch/copy/table/' (format parquet)
query TT
EXPLAIN COPY source_table to 'test_files/scratch/copy/table/' (format parquet, per_thread_output true)

# Copy more files to directory via query
query IT
COPY (select * from source_table UNION ALL select * from source_table) to 'test_files/scratch/copy/table/' (format parquet);
----
4

# validate multiple parquet file output
statement ok
CREATE EXTERNAL TABLE validate_parquet STORED AS PARQUET LOCATION 'test_files/scratch/copy/table/';

query IT
select * from validate_parquet;
----
1 Foo
2 Bar
1 Foo
2 Bar
1 Foo
2 Bar

query ?
copy (values (struct(timestamp '2021-01-01 01:00:01', 1)), (struct(timestamp '2022-01-01 01:00:01', 2)), 
(struct(timestamp '2023-01-03 01:00:01', 3)), (struct(timestamp '2024-01-01 01:00:01', 4)))
to 'test_files/scratch/copy/table_nested2/' (format parquet);
----
4

statement ok
CREATE EXTERNAL TABLE validate_parquet_nested2 STORED AS PARQUET LOCATION 'test_files/scratch/copy/table_nested2/';

query ?
select * from validate_parquet_nested2;
----
{c0: 2021-01-01T01:00:01, c1: 1}
{c0: 2022-01-01T01:00:01, c1: 2}
{c0: 2023-01-03T01:00:01, c1: 3}
{c0: 2024-01-01T01:00:01, c1: 4}

query ??
COPY 
(values (struct ('foo', (struct ('foo', make_array(struct('a',1), struct('b',2))))), make_array(timestamp '2023-01-01 01:00:01',timestamp '2023-01-01 01:00:01')), 
(struct('bar', (struct ('foo', make_array(struct('aa',10), struct('bb',20))))), make_array(timestamp '2024-01-01 01:00:01', timestamp '2024-01-01 01:00:01'))) 
to 'test_files/scratch/copy/table_nested/' (format parquet);
----
2

statement ok
CREATE EXTERNAL TABLE validate_parquet_nested STORED AS PARQUET 
LOCATION 'test_files/scratch/copy/table_nested/';

query ??
select * from validate_parquet_nested;
----
{c0: foo, c1: {c0: foo, c1: [{c0: a, c1: 1}, {c0: b, c1: 2}]}} [2023-01-01T01:00:01, 2023-01-01T01:00:01]
{c0: bar, c1: {c0: foo, c1: [{c0: aa, c1: 10}, {c0: bb, c1: 20}]}} [2024-01-01T01:00:01, 2024-01-01T01:00:01]

query ?
copy (values ([struct('foo', 1), struct('bar', 2)])) 
to 'test_files/scratch/copy/array_of_struct/'
(format parquet);
----
1

statement ok
CREATE EXTERNAL TABLE validate_array_of_struct 
STORED AS PARQUET LOCATION 'test_files/scratch/copy/array_of_struct/';

query ?
select * from validate_array_of_struct;
----
[{c0: foo, c1: 1}, {c0: bar, c1: 2}]

query ?
copy (values (struct('foo', [1,2,3], struct('bar', [2,3,4])))) 
to 'test_files/scratch/copy/struct_with_array/'
(format parquet);
----
1

statement ok
CREATE EXTERNAL TABLE validate_struct_with_array
STORED AS PARQUET LOCATION 'test_files/scratch/copy/struct_with_array/';

query ?
select * from validate_struct_with_array;
----
{c0: foo, c1: [1, 2, 3], c2: {c0: bar, c1: [2, 3, 4]}}


# Copy parquet with all supported statment overrides
query IT
COPY source_table
TO 'test_files/scratch/copy/table_with_options/'
(format parquet,
compression snappy,
'compression::col1' 'zstd(5)',
'compression::col2' snappy,
max_row_group_size 12345,
data_pagesize_limit 1234,
write_batch_size 1234,
writer_version 2.0,
dictionary_page_size_limit 123,
created_by 'DF copy.slt',
column_index_truncate_length 123,
data_page_row_count_limit 1234,
bloom_filter_enabled true,
'bloom_filter_enabled::col1' false,
'bloom_filter_fpp::col2' 0.456,
'bloom_filter_ndv::col2' 456,
encoding plain,
'encoding::col1' DELTA_BINARY_PACKED,
'dictionary_enabled::col2' true,
dictionary_enabled false,
statistics_enabled page,
'statistics_enabled::col2' none,
max_statistics_size 123,
bloom_filter_fpp 0.001,
bloom_filter_ndv 100
)
----
2

# validate multiple parquet file output with all options set
statement ok
CREATE EXTERNAL TABLE validate_parquet_with_options STORED AS PARQUET LOCATION 'test_files/scratch/copy/table_with_options/';

query IT
select * from validate_parquet_with_options;
----
1 Foo
2 Bar

# Copy from table to single file
query IT
COPY source_table to 'test_files/scratch/copy/table.parquet';
----
2

# validate single parquet file output
statement ok
CREATE EXTERNAL TABLE validate_parquet_single STORED AS PARQUET LOCATION 'test_files/scratch/copy/table.parquet';

query IT
select * from validate_parquet_single;
----
1 Foo
2 Bar

# copy from table to folder of compressed json files
query IT
COPY source_table  to 'test_files/scratch/copy/table_json_gz' (format json, compression 'gzip');
----
2

# validate folder of csv files
statement ok
CREATE EXTERNAL TABLE validate_json_gz STORED AS json COMPRESSION TYPE gzip LOCATION 'test_files/scratch/copy/table_json_gz';

query IT
select * from validate_json_gz;
----
1 Foo
2 Bar

# copy from table to folder of compressed csv files
query IT
COPY source_table  to 'test_files/scratch/copy/table_csv' (format csv, header false, compression 'gzip');
----
2

# validate folder of csv files
statement ok
CREATE EXTERNAL TABLE validate_csv STORED AS csv COMPRESSION TYPE gzip LOCATION 'test_files/scratch/copy/table_csv';

query IT
select * from validate_csv;
----
1 Foo
2 Bar

# Copy from table to single csv
query IT
COPY source_table  to 'test_files/scratch/copy/table.csv';
----
2

# Validate single csv output
statement ok
CREATE EXTERNAL TABLE validate_single_csv STORED AS csv WITH HEADER ROW LOCATION 'test_files/scratch/copy/table.csv';

query IT
select * from validate_single_csv;
----
1 Foo
2 Bar

# Copy from table to folder of json
query IT
COPY source_table to 'test_files/scratch/copy/table_json' (format json);
----
2

# Validate json output
statement ok
CREATE EXTERNAL TABLE validate_json STORED AS json LOCATION 'test_files/scratch/copy/table_json';

query IT
select * from validate_json;
----
1 Foo
2 Bar

# Copy from table to single json file
query IT
COPY source_table  to 'test_files/scratch/copy/table.json';
----
2

# Validate single JSON file`
statement ok
CREATE EXTERNAL TABLE validate_single_json STORED AS json LOCATION 'test_files/scratch/copy/table_json';

query IT
select * from validate_single_json;
----
1 Foo
2 Bar

# COPY csv files with all options set
query IT
COPY source_table
to 'test_files/scratch/copy/table_csv_with_options'
(format csv,
header false,
compression 'uncompressed',
datetime_format '%FT%H:%M:%S.%9f',
delimiter ';',
null_value 'NULLVAL');
----
2

# Validate single csv output
statement ok
CREATE EXTERNAL TABLE validate_csv_with_options
STORED AS csv
LOCATION 'test_files/scratch/copy/table_csv_with_options';

query T
select * from validate_csv_with_options;
----
1;Foo
2;Bar

# Copy from table to single arrow file
query IT
COPY source_table to 'test_files/scratch/copy/table.arrow';
----
2

# Validate single csv output
statement ok
CREATE EXTERNAL TABLE validate_arrow_file
STORED AS arrow
LOCATION 'test_files/scratch/copy/table.arrow';

query IT
select * from validate_arrow_file;
----
1 Foo
2 Bar

# Copy from dict encoded values to single arrow file
query T?
COPY (values 
('c', arrow_cast('foo', 'Dictionary(Int32, Utf8)')), ('d', arrow_cast('bar', 'Dictionary(Int32, Utf8)'))) 
to 'test_files/scratch/copy/table_dict.arrow';
----
2

# Validate single csv output
statement ok
CREATE EXTERNAL TABLE validate_arrow_file_dict
STORED AS arrow
LOCATION 'test_files/scratch/copy/table_dict.arrow';

query T?
select * from validate_arrow_file_dict;
----
c foo
d bar


# Copy from table to folder of json
query IT
COPY source_table to 'test_files/scratch/copy/table_arrow' (format arrow);
----
2

# Validate json output
statement ok
CREATE EXTERNAL TABLE validate_arrow STORED AS arrow LOCATION 'test_files/scratch/copy/table_arrow';

query IT
select * from validate_arrow;
----
1 Foo
2 Bar


# Error cases:

# Copy from table with options
query error DataFusion error: Invalid or Unsupported Configuration: Found unsupported option row_group_size with value 55 for JSON format!
COPY source_table  to 'test_files/scratch/copy/table.json' (row_group_size 55);

# Incomplete statement
query error DataFusion error: SQL error: ParserError\("Expected \), found: EOF"\)
COPY (select col2, sum(col1) from source_table

# Copy from table with non literal
query error DataFusion error: SQL error: ParserError\("Expected ',' or '\)' after option definition, found: \+"\)
COPY source_table  to '/tmp/table.parquet' (row_group_size 55 + 102);
