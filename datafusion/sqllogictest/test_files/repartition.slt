# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at

#   http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

##########
# Tests for repartitioning
##########

# Set 4 partitions for deterministic output plans
statement ok
set datafusion.execution.target_partitions = 4;

statement ok
COPY  (VALUES (1, 2), (2, 5), (3, 2), (4, 5), (5, 0)) TO 'test_files/scratch/repartition/parquet_table/2.parquet'
STORED AS PARQUET;

statement ok
CREATE EXTERNAL TABLE parquet_table(column1 int, column2 int)
STORED AS PARQUET
LOCATION 'test_files/scratch/repartition/parquet_table/';

# enable round robin repartitioning
statement ok
set datafusion.optimizer.enable_round_robin_repartition = true;

query TT
EXPLAIN SELECT column1, SUM(column2) FROM parquet_table GROUP BY column1;
----
logical_plan
01)Aggregate: groupBy=[[parquet_table.column1]], aggr=[[sum(CAST(parquet_table.column2 AS Int64))]]
02)--TableScan: parquet_table projection=[column1, column2]
physical_plan
01)AggregateExec: mode=FinalPartitioned, gby=[column1@0 as column1], aggr=[sum(parquet_table.column2)]
02)--CoalesceBatchesExec: target_batch_size=8192
03)----RepartitionExec: partitioning=Hash([column1@0], 4), input_partitions=4
04)------RepartitionExec: partitioning=RoundRobinBatch(4), input_partitions=1
05)--------AggregateExec: mode=Partial, gby=[column1@0 as column1], aggr=[sum(parquet_table.column2)]
06)----------DataSourceExec: file_groups={1 group: [[WORKSPACE_ROOT/datafusion/sqllogictest/test_files/scratch/repartition/parquet_table/2.parquet]]}, projection=[column1, column2], file_type=parquet

# disable round robin repartitioning
statement ok
set datafusion.optimizer.enable_round_robin_repartition = false;

query TT
EXPLAIN SELECT column1, SUM(column2) FROM parquet_table GROUP BY column1;
----
logical_plan
01)Aggregate: groupBy=[[parquet_table.column1]], aggr=[[sum(CAST(parquet_table.column2 AS Int64))]]
02)--TableScan: parquet_table projection=[column1, column2]
physical_plan
01)AggregateExec: mode=FinalPartitioned, gby=[column1@0 as column1], aggr=[sum(parquet_table.column2)]
02)--CoalesceBatchesExec: target_batch_size=8192
03)----RepartitionExec: partitioning=Hash([column1@0], 4), input_partitions=1
04)------AggregateExec: mode=Partial, gby=[column1@0 as column1], aggr=[sum(parquet_table.column2)]
05)--------DataSourceExec: file_groups={1 group: [[WORKSPACE_ROOT/datafusion/sqllogictest/test_files/scratch/repartition/parquet_table/2.parquet]]}, projection=[column1, column2], file_type=parquet


# Cleanup
statement ok
DROP TABLE parquet_table;



# Unbounded repartition
# See https://github.com/apache/datafusion/issues/5278
# Set up unbounded table and run a query - the query plan should display a `RepartitionExec`
# and a `CoalescePartitionsExec`
statement ok
CREATE UNBOUNDED EXTERNAL TABLE sink_table (
        c1  VARCHAR NOT NULL,
        c2  TINYINT NOT NULL,
        c3  SMALLINT NOT NULL,
        c4  SMALLINT NOT NULL,
        c5  INTEGER NOT NULL,
        c6  BIGINT NOT NULL,
        c7  SMALLINT NOT NULL,
        c8  INT NOT NULL,
        c9  INT UNSIGNED NOT NULL,
        c10 BIGINT UNSIGNED NOT NULL,
        c11 FLOAT NOT NULL,
        c12 DOUBLE NOT NULL,
        c13 VARCHAR NOT NULL
    )
STORED AS CSV
LOCATION '../../testing/data/csv/aggregate_test_100.csv'
OPTIONS ('format.has_header' 'true');

query TII
SELECT c1, c2, c3 FROM sink_table WHERE c3 > 0 LIMIT 5;
----
c 2 1
b 1 29
e 3 104
a 3 13
d 1 38

statement ok
set datafusion.execution.target_partitions = 3;

statement ok
set datafusion.optimizer.enable_round_robin_repartition = true;

query TT
EXPLAIN SELECT c1, c2, c3 FROM sink_table WHERE c3 > 0 LIMIT 5;
----
logical_plan
01)Limit: skip=0, fetch=5
02)--Filter: sink_table.c3 > Int16(0)
03)----TableScan: sink_table projection=[c1, c2, c3]
physical_plan
01)CoalescePartitionsExec: fetch=5
02)--CoalesceBatchesExec: target_batch_size=8192, fetch=5
03)----FilterExec: c3@2 > 0
04)------RepartitionExec: partitioning=RoundRobinBatch(3), input_partitions=1
05)--------StreamingTableExec: partition_sizes=1, projection=[c1, c2, c3], infinite_source=true

# Start repratition on empty column test.
# See https://github.com/apache/datafusion/issues/12057

statement ok
CREATE TABLE t1(v1 int);

statement ok
INSERT INTO t1 values(42);

query I
SELECT sum(1) OVER (PARTITION BY false=false) 
FROM t1 WHERE ((false > (v1 = v1)) IS DISTINCT FROM true);
----
1

statement ok
DROP TABLE t1;

# End repartition on empty columns test

# Start spilling tests
# Spilling is hard to reproduce with real data / queries
# The memory limit was tuned to this specific datset (which was already used in `window.slt`)
# by hand to trigger spilling without being so low that the query would not succeed.
# Before we introduced spilling to `RepartitionExec` this query could not complete.

statement ok
CREATE UNBOUNDED EXTERNAL TABLE annotated_data_infinite2 (
  a0 INTEGER,
  a INTEGER,
  b INTEGER,
  c INTEGER,
  d INTEGER
)
STORED AS CSV
WITH ORDER (a ASC, b ASC, c ASC)
LOCATION '../../datafusion/core/tests/data/window_2.csv'
OPTIONS ('format.has_header' 'true');

statement ok
SET datafusion.runtime.memory_limit = '12K';

query IIII
SELECT SUM(a) OVER(partition by a, b order by c) as sum1,
  SUM(a) OVER(partition by b, a order by c) as sum2,
  SUM(a) OVER(partition by a, d order by b) as sum3,
  SUM(a) OVER(partition by d order by a) as sum4
FROM annotated_data_infinite2;
----
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
2 2 2 4
14 14 4 4
12 12 2 4
25 25 4 4
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
1 1 3 8
2 2 8 8
16 16 3 8
7 7 8 8
21 21 3 8
18 18 8 8
19 19 8 8
21 21 8 8
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
0 0 0 0
3 3 10 15
1 1 11 11
4 4 10 15
3 3 11 11
5 5 6 12
4 4 15 15
6 6 4 11
5 5 12 12
7 7 10 15
6 6 11 11
8 8 10 15
8 8 12 12
9 9 10 15
9 9 11 11
10 10 4 11
10 10 15 15
11 11 6 12
11 11 15 15
13 13 10 15
12 12 15 15
14 14 6 12
13 13 12 12
15 15 6 12
15 15 12 12
17 17 4 11
16 16 15 15
18 18 6 12
17 17 11 11
19 19 10 15
20 20 11 11
20 20 10 15
22 22 12 12
22 22 4 11
23 23 11 11
23 23 10 15
24 24 12 12
24 24 10 15
25 25 6 12

# End spilling tests
