<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Configuration Settings &#8212; Apache DataFusion  documentation</title>
    
    <link href="../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
  
    
    <link rel="stylesheet"
      href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
    <link rel="preload" as="font" type="font/woff2" crossorigin
      href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">
  
    
      
  
    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/pydata-sphinx-theme.css?v=1140d252" />
    <link rel="stylesheet" type="text/css" href="../_static/theme_overrides.css?v=c6d785ac" />
    
    <link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">
  
    <script src="../_static/documentation_options.js?v=8a448e45"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Reading Explain Plans" href="explain-usage.html" />
    <link rel="prev" title="Prepared Statements" href="sql/prepared_statements.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    


    <div class="container-xl">
      <div class="row">
          
            
            <!-- Only show if we have sidebars configured, else just a small margin  -->
            <div class="col-12 col-md-3 bd-sidebar">
              <div class="sidebar-start-items">

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search the docs ..." aria-label="Search the docs ..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <div class="bd-toc-item active">
    
    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  ASF Links
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://apache.org">
   Apache Software Foundation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://www.apache.org/licenses/">
   License
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://www.apache.org/foundation/sponsorship.html">
   Donate
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://www.apache.org/foundation/thanks.html">
   Thanks
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://www.apache.org/security/">
   Security
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Links
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/apache/datafusion">
   GitHub and Issue Tracker
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://crates.io/crates/datafusion">
   crates.io
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://docs.rs/datafusion/latest/datafusion/">
   API Docs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://datafusion.apache.org/blog/">
   Blog
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://github.com/apache/datafusion/blob/main/CODE_OF_CONDUCT.md">
   Code of conduct
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../download.html">
   Download
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  User Guide
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="introduction.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="example-usage.html">
   Example Usage
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="features.html">
   Features
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="concepts-readings-events.html">
   Concepts, Readings, Events
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="crate-configuration.html">
   Crate Configuration
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="cli/index.html">
   DataFusion CLI
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="cli/overview.html">
     Overview
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cli/installation.html">
     Installation
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cli/usage.html">
     Usage
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cli/datasources.html">
     Local Files / Directories
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dataframe.html">
   DataFrame API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="expressions.html">
   Expression API
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="sql/index.html">
   SQL Reference
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="sql/data_types.html">
     Data Types
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sql/select.html">
     SELECT syntax
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sql/subqueries.html">
     Subqueries
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sql/ddl.html">
     DDL
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sql/dml.html">
     DML
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sql/explain.html">
     EXPLAIN
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sql/information_schema.html">
     Information Schema
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sql/operators.html">
     Operators and Literals
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sql/aggregate_functions.html">
     Aggregate Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sql/window_functions.html">
     Window Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sql/scalar_functions.html">
     Scalar Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sql/special_functions.html">
     Special Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sql/format_options.html">
     Format Options
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="sql/prepared_statements.html">
     Prepared Statements
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Configuration Settings
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="explain-usage.html">
   Reading Explain Plans
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="faq.html">
   Frequently Asked Questions
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Library User Guide
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../library-user-guide/index.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../library-user-guide/upgrading.html">
   Upgrade Guides
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../library-user-guide/extensions.html">
   Extensions List
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../library-user-guide/using-the-sql-api.html">
   Using the SQL API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../library-user-guide/working-with-exprs.html">
   Working with
   <code class="docutils literal notranslate">
    <span class="pre">
     Expr
    </span>
   </code>
   s
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../library-user-guide/using-the-dataframe-api.html">
   Using the DataFrame API
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../library-user-guide/building-logical-plans.html">
   Building Logical Plans
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../library-user-guide/catalogs.html">
   Catalogs, Schemas, and Tables
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../library-user-guide/functions/index.html">
   Functions
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../library-user-guide/functions/adding-udfs.html">
     Adding User Defined Functions: Scalar/Window/Aggregate/Table Functions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../library-user-guide/functions/spark.html">
     Spark Compatible Functions
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../library-user-guide/custom-table-providers.html">
   Custom Table Provider
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../library-user-guide/table-constraints.html">
   Table Constraint Enforcement
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../library-user-guide/extending-operators.html">
   Extending DataFusion’s operators: custom LogicalPlan and Execution Plans
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../library-user-guide/profiling.html">
   Profiling Cookbook
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../library-user-guide/query-optimizer.html">
   DataFusion Query Optimizer
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Contributor Guide
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../contributor-guide/index.html">
   Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../contributor-guide/communication.html">
   Communication
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../contributor-guide/development_environment.html">
   Development Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../contributor-guide/architecture.html">
   Architecture
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../contributor-guide/testing.html">
   Testing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../contributor-guide/api-health.html">
   API health policy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../contributor-guide/howtos.html">
   HOWTOs
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../contributor-guide/roadmap.html">
   Roadmap
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../contributor-guide/governance.html">
   Governance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../contributor-guide/inviting.html">
   Inviting New Committers and PMC Members
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../contributor-guide/specification/index.html">
   Specifications
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../contributor-guide/specification/invariants.html">
     Invariants
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../contributor-guide/specification/output-field-name-semantic.html">
     Output field name semantics
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../contributor-guide/gsoc_application_guidelines.html">
   GSoC Application Guidelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../contributor-guide/gsoc_project_ideas.html">
   GSoC Project Ideas
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  DataFusion Subprojects
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://arrow.apache.org/ballista/">
   DataFusion Ballista
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://datafusion.apache.org/comet/">
   DataFusion Comet
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference external" href="https://datafusion.apache.org/python/">
   DataFusion Python
  </a>
 </li>
</ul>

    
  </div>

  <a class="navbar-brand" href="../index.html">
    <img src="../_static/images/2x_bgwhite_original.png" class="logo" alt="logo">
  </a>
</nav>

              </div>
              <div class="sidebar-end-items">
              </div>
            </div>
            
          

          
          <div class="d-none d-xl-block col-xl-2 bd-toc">
            
              
              <div class="toc-item">
                
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   Configuration Settings
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#runtime-configuration-settings">
   Runtime Configuration Settings
  </a>
 </li>
</ul>

</nav>
              </div>
              
              <div class="toc-item">
                

<div class="tocsection editthispage">
    <a href="https://github.com/apache/arrow-datafusion/edit/main/docs/source/user-guide/configs.md">
        <i class="fas fa-pencil-alt"></i> Edit this page
    </a>
</div>

              </div>
              
            
          </div>
          

          
          
            
          
          <main class="col-12 col-md-9 col-xl-7 py-md-5 pl-md-5 pr-md-4 bd-content" role="main">
              
              <div>
                
  <!---
  Licensed to the Apache Software Foundation (ASF) under one
  or more contributor license agreements.  See the NOTICE file
  distributed with this work for additional information
  regarding copyright ownership.  The ASF licenses this file
  to you under the Apache License, Version 2.0 (the
  "License"); you may not use this file except in compliance
  with the License.  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing,
  software distributed under the License is distributed on an
  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
  KIND, either express or implied.  See the License for the
  specific language governing permissions and limitations
  under the License.
-->
<!---
This file was generated by the dev/update_config_docs.sh script.
Do not edit it manually as changes will be overwritten.
Instead, edit dev/update_config_docs.sh or the docstrings in datafusion/core/src/config.rs.
-->
<section id="configuration-settings">
<h1>Configuration Settings<a class="headerlink" href="#configuration-settings" title="Link to this heading">¶</a></h1>
<p>The following configuration options can be passed to <code class="docutils literal notranslate"><span class="pre">SessionConfig</span></code> to control various aspects of query execution.</p>
<p>For applications which do not expose <code class="docutils literal notranslate"><span class="pre">SessionConfig</span></code>, like <code class="docutils literal notranslate"><span class="pre">datafusion-cli</span></code>, these options may also be set via environment variables.
To construct a session with options from the environment, use <code class="docutils literal notranslate"><span class="pre">SessionConfig::from_env</span></code>.
The name of the environment variable is the option’s key, transformed to uppercase and with periods replaced with underscores.
For example, to configure <code class="docutils literal notranslate"><span class="pre">datafusion.execution.batch_size</span></code> you would set the <code class="docutils literal notranslate"><span class="pre">DATAFUSION_EXECUTION_BATCH_SIZE</span></code> environment variable.
Values are parsed according to the <a class="reference external" href="https://docs.rs/arrow/latest/arrow/compute/kernels/cast/fn.cast.html">same rules used in casts from Utf8</a>.
If the value in the environment variable cannot be cast to the type of the configuration option, the default value will be used instead and a warning emitted.
Environment variables are read during <code class="docutils literal notranslate"><span class="pre">SessionConfig</span></code> initialisation so they must be set beforehand and will not affect running sessions.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>key</p></th>
<th class="head"><p>default</p></th>
<th class="head"><p>description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>datafusion.catalog.create_default_catalog_and_schema</p></td>
<td><p>true</p></td>
<td><p>Whether the default catalog and schema should be created automatically.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.catalog.default_catalog</p></td>
<td><p>datafusion</p></td>
<td><p>The default catalog name - this impacts what SQL queries use if not specified</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.catalog.default_schema</p></td>
<td><p>public</p></td>
<td><p>The default schema name - this impacts what SQL queries use if not specified</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.catalog.information_schema</p></td>
<td><p>false</p></td>
<td><p>Should DataFusion provide access to <code class="docutils literal notranslate"><span class="pre">information_schema</span></code> virtual tables for displaying schema information</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.catalog.location</p></td>
<td><p>NULL</p></td>
<td><p>Location scanned to load tables for <code class="docutils literal notranslate"><span class="pre">default</span></code> schema</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.catalog.format</p></td>
<td><p>NULL</p></td>
<td><p>Type of <code class="docutils literal notranslate"><span class="pre">TableProvider</span></code> to use when loading <code class="docutils literal notranslate"><span class="pre">default</span></code> schema</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.catalog.has_header</p></td>
<td><p>true</p></td>
<td><p>Default value for <code class="docutils literal notranslate"><span class="pre">format.has_header</span></code> for <code class="docutils literal notranslate"><span class="pre">CREATE</span> <span class="pre">EXTERNAL</span> <span class="pre">TABLE</span></code> if not specified explicitly in the statement.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.catalog.newlines_in_values</p></td>
<td><p>false</p></td>
<td><p>Specifies whether newlines in (quoted) CSV values are supported. This is the default value for <code class="docutils literal notranslate"><span class="pre">format.newlines_in_values</span></code> for <code class="docutils literal notranslate"><span class="pre">CREATE</span> <span class="pre">EXTERNAL</span> <span class="pre">TABLE</span></code> if not specified explicitly in the statement. Parsing newlines in quoted values may be affected by execution behaviour such as parallel file scanning. Setting this to <code class="docutils literal notranslate"><span class="pre">true</span></code> ensures that newlines in values are parsed successfully, which may reduce performance.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.batch_size</p></td>
<td><p>8192</p></td>
<td><p>Default batch size while creating new batches, it’s especially useful for buffer-in-memory batches since creating tiny batches would result in too much metadata memory consumption</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.coalesce_batches</p></td>
<td><p>true</p></td>
<td><p>When set to true, record batches will be examined between each operator and small batches will be coalesced into larger batches. This is helpful when there are highly selective filters or joins that could produce tiny output batches. The target batch size is determined by the configuration setting</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.collect_statistics</p></td>
<td><p>true</p></td>
<td><p>Should DataFusion collect statistics when first creating a table. Has no effect after the table is created. Applies to the default <code class="docutils literal notranslate"><span class="pre">ListingTableProvider</span></code> in DataFusion. Defaults to true.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.target_partitions</p></td>
<td><p>0</p></td>
<td><p>Number of partitions for query execution. Increasing partitions can increase concurrency. Defaults to the number of CPU cores on the system</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.time_zone</p></td>
<td><p>+00:00</p></td>
<td><p>The default time zone Some functions, e.g. <code class="docutils literal notranslate"><span class="pre">EXTRACT(HOUR</span> <span class="pre">from</span> <span class="pre">SOME_TIME)</span></code>, shift the underlying datetime according to this time zone, and then extract the hour</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.parquet.enable_page_index</p></td>
<td><p>true</p></td>
<td><p>(reading) If true, reads the Parquet data page level metadata (the Page Index), if present, to reduce the I/O and number of rows decoded.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.parquet.pruning</p></td>
<td><p>true</p></td>
<td><p>(reading) If true, the parquet reader attempts to skip entire row groups based on the predicate in the query and the metadata (min/max values) stored in the parquet file</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.parquet.skip_metadata</p></td>
<td><p>true</p></td>
<td><p>(reading) If true, the parquet reader skip the optional embedded metadata that may be in the file Schema. This setting can help avoid schema conflicts when querying multiple parquet files with schemas containing compatible types but different metadata</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.parquet.metadata_size_hint</p></td>
<td><p>NULL</p></td>
<td><p>(reading) If specified, the parquet reader will try and fetch the last <code class="docutils literal notranslate"><span class="pre">size_hint</span></code> bytes of the parquet file optimistically. If not specified, two reads are required: One read to fetch the 8-byte parquet footer and another to fetch the metadata length encoded in the footer</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.parquet.pushdown_filters</p></td>
<td><p>false</p></td>
<td><p>(reading) If true, filter expressions are be applied during the parquet decoding operation to reduce the number of rows decoded. This optimization is sometimes called “late materialization”.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.parquet.reorder_filters</p></td>
<td><p>false</p></td>
<td><p>(reading) If true, filter expressions evaluated during the parquet decoding operation will be reordered heuristically to minimize the cost of evaluation. If false, the filters are applied in the same order as written in the query</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.parquet.schema_force_view_types</p></td>
<td><p>true</p></td>
<td><p>(reading) If true, parquet reader will read columns of <code class="docutils literal notranslate"><span class="pre">Utf8/Utf8Large</span></code> with <code class="docutils literal notranslate"><span class="pre">Utf8View</span></code>, and <code class="docutils literal notranslate"><span class="pre">Binary/BinaryLarge</span></code> with <code class="docutils literal notranslate"><span class="pre">BinaryView</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.parquet.binary_as_string</p></td>
<td><p>false</p></td>
<td><p>(reading) If true, parquet reader will read columns of <code class="docutils literal notranslate"><span class="pre">Binary/LargeBinary</span></code> with <code class="docutils literal notranslate"><span class="pre">Utf8</span></code>, and <code class="docutils literal notranslate"><span class="pre">BinaryView</span></code> with <code class="docutils literal notranslate"><span class="pre">Utf8View</span></code>. Parquet files generated by some legacy writers do not correctly set the UTF8 flag for strings, causing string columns to be loaded as BLOB instead.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.parquet.coerce_int96</p></td>
<td><p>NULL</p></td>
<td><p>(reading) If true, parquet reader will read columns of physical type int96 as originating from a different resolution than nanosecond. This is useful for reading data from systems like Spark which stores microsecond resolution timestamps in an int96 allowing it to write values with a larger date range than 64-bit timestamps with nanosecond resolution.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.parquet.bloom_filter_on_read</p></td>
<td><p>true</p></td>
<td><p>(reading) Use any available bloom filters when reading parquet files</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.parquet.data_pagesize_limit</p></td>
<td><p>1048576</p></td>
<td><p>(writing) Sets best effort maximum size of data page in bytes</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.parquet.write_batch_size</p></td>
<td><p>1024</p></td>
<td><p>(writing) Sets write_batch_size in bytes</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.parquet.writer_version</p></td>
<td><p>1.0</p></td>
<td><p>(writing) Sets parquet writer version valid values are “1.0” and “2.0”</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.parquet.skip_arrow_metadata</p></td>
<td><p>false</p></td>
<td><p>(writing) Skip encoding the embedded arrow metadata in the KV_meta This is analogous to the <code class="docutils literal notranslate"><span class="pre">ArrowWriterOptions::with_skip_arrow_metadata</span></code>. Refer to <a class="reference external" href="https://docs.rs/parquet/53.3.0/parquet/arrow/arrow_writer/struct.ArrowWriterOptions.html#method.with_skip_arrow_metadata">https://docs.rs/parquet/53.3.0/parquet/arrow/arrow_writer/struct.ArrowWriterOptions.html#method.with_skip_arrow_metadata</a></p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.parquet.compression</p></td>
<td><p>zstd(3)</p></td>
<td><p>(writing) Sets default parquet compression codec. Valid values are: uncompressed, snappy, gzip(level), lzo, brotli(level), lz4, zstd(level), and lz4_raw. These values are not case sensitive. If NULL, uses default parquet writer setting Note that this default setting is not the same as the default parquet writer setting.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.parquet.dictionary_enabled</p></td>
<td><p>true</p></td>
<td><p>(writing) Sets if dictionary encoding is enabled. If NULL, uses default parquet writer setting</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.parquet.dictionary_page_size_limit</p></td>
<td><p>1048576</p></td>
<td><p>(writing) Sets best effort maximum dictionary page size, in bytes</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.parquet.statistics_enabled</p></td>
<td><p>page</p></td>
<td><p>(writing) Sets if statistics are enabled for any column Valid values are: “none”, “chunk”, and “page” These values are not case sensitive. If NULL, uses default parquet writer setting</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.parquet.max_statistics_size</p></td>
<td><p>4096</p></td>
<td><p>(writing) Sets max statistics size for any column. If NULL, uses default parquet writer setting max_statistics_size is deprecated, currently it is not being used</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.parquet.max_row_group_size</p></td>
<td><p>1048576</p></td>
<td><p>(writing) Target maximum number of rows in each row group (defaults to 1M rows). Writing larger row groups requires more memory to write, but can get better compression and be faster to read.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.parquet.created_by</p></td>
<td><p>datafusion version 48.0.0</p></td>
<td><p>(writing) Sets “created by” property</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.parquet.column_index_truncate_length</p></td>
<td><p>64</p></td>
<td><p>(writing) Sets column index truncate length</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.parquet.statistics_truncate_length</p></td>
<td><p>NULL</p></td>
<td><p>(writing) Sets statictics truncate length. If NULL, uses default parquet writer setting</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.parquet.data_page_row_count_limit</p></td>
<td><p>20000</p></td>
<td><p>(writing) Sets best effort maximum number of rows in data page</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.parquet.encoding</p></td>
<td><p>NULL</p></td>
<td><p>(writing) Sets default encoding for any column. Valid values are: plain, plain_dictionary, rle, bit_packed, delta_binary_packed, delta_length_byte_array, delta_byte_array, rle_dictionary, and byte_stream_split. These values are not case sensitive. If NULL, uses default parquet writer setting</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.parquet.bloom_filter_on_write</p></td>
<td><p>false</p></td>
<td><p>(writing) Write bloom filters for all columns when creating parquet files</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.parquet.bloom_filter_fpp</p></td>
<td><p>NULL</p></td>
<td><p>(writing) Sets bloom filter false positive probability. If NULL, uses default parquet writer setting</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.parquet.bloom_filter_ndv</p></td>
<td><p>NULL</p></td>
<td><p>(writing) Sets bloom filter number of distinct values. If NULL, uses default parquet writer setting</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.parquet.allow_single_file_parallelism</p></td>
<td><p>true</p></td>
<td><p>(writing) Controls whether DataFusion will attempt to speed up writing parquet files by serializing them in parallel. Each column in each row group in each output file are serialized in parallel leveraging a maximum possible core count of n_files<em>n_row_groups</em>n_columns.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.parquet.maximum_parallel_row_group_writers</p></td>
<td><p>1</p></td>
<td><p>(writing) By default parallel parquet writer is tuned for minimum memory usage in a streaming execution plan. You may see a performance benefit when writing large parquet files by increasing maximum_parallel_row_group_writers and maximum_buffered_record_batches_per_stream if your system has idle cores and can tolerate additional memory usage. Boosting these values is likely worthwhile when writing out already in-memory data, such as from a cached data frame.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.parquet.maximum_buffered_record_batches_per_stream</p></td>
<td><p>2</p></td>
<td><p>(writing) By default parallel parquet writer is tuned for minimum memory usage in a streaming execution plan. You may see a performance benefit when writing large parquet files by increasing maximum_parallel_row_group_writers and maximum_buffered_record_batches_per_stream if your system has idle cores and can tolerate additional memory usage. Boosting these values is likely worthwhile when writing out already in-memory data, such as from a cached data frame.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.planning_concurrency</p></td>
<td><p>0</p></td>
<td><p>Fan-out during initial physical planning. This is mostly use to plan <code class="docutils literal notranslate"><span class="pre">UNION</span></code> children in parallel. Defaults to the number of CPU cores on the system</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.skip_physical_aggregate_schema_check</p></td>
<td><p>false</p></td>
<td><p>When set to true, skips verifying that the schema produced by planning the input of <code class="docutils literal notranslate"><span class="pre">LogicalPlan::Aggregate</span></code> exactly matches the schema of the input plan. When set to false, if the schema does not match exactly (including nullability and metadata), a planning error will be raised. This is used to workaround bugs in the planner that are now caught by the new schema verification step.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.spill_compression</p></td>
<td><p>uncompressed</p></td>
<td><p>Sets the compression codec used when spilling data to disk. Since datafusion writes spill files using the Arrow IPC Stream format, only codecs supported by the Arrow IPC Stream Writer are allowed. Valid values are: uncompressed, lz4_frame, zstd. Note: lz4_frame offers faster (de)compression, but typically results in larger spill files. In contrast, zstd achieves higher compression ratios at the cost of slower (de)compression speed.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.sort_spill_reservation_bytes</p></td>
<td><p>10485760</p></td>
<td><p>Specifies the reserved memory for each spillable sort operation to facilitate an in-memory merge. When a sort operation spills to disk, the in-memory data must be sorted and merged before being written to a file. This setting reserves a specific amount of memory for that in-memory sort/merge process. Note: This setting is irrelevant if the sort operation cannot spill (i.e., if there’s no <code class="docutils literal notranslate"><span class="pre">DiskManager</span></code> configured).</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.sort_in_place_threshold_bytes</p></td>
<td><p>1048576</p></td>
<td><p>When sorting, below what size should data be concatenated and sorted in a single RecordBatch rather than sorted in batches and merged.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.meta_fetch_concurrency</p></td>
<td><p>32</p></td>
<td><p>Number of files to read in parallel when inferring schema and statistics</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.minimum_parallel_output_files</p></td>
<td><p>4</p></td>
<td><p>Guarantees a minimum level of output files running in parallel. RecordBatches will be distributed in round robin fashion to each parallel writer. Each writer is closed and a new file opened once soft_max_rows_per_output_file is reached.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.soft_max_rows_per_output_file</p></td>
<td><p>50000000</p></td>
<td><p>Target number of rows in output files when writing multiple. This is a soft max, so it can be exceeded slightly. There also will be one file smaller than the limit if the total number of rows written is not roughly divisible by the soft max</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.max_buffered_batches_per_output_file</p></td>
<td><p>2</p></td>
<td><p>This is the maximum number of RecordBatches buffered for each output file being worked. Higher values can potentially give faster write performance at the cost of higher peak memory consumption</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.listing_table_ignore_subdirectory</p></td>
<td><p>true</p></td>
<td><p>Should sub directories be ignored when scanning directories for data files. Defaults to true (ignores subdirectories), consistent with Hive. Note that this setting does not affect reading partitioned tables (e.g. <code class="docutils literal notranslate"><span class="pre">/table/year=2021/month=01/data.parquet</span></code>).</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.enable_recursive_ctes</p></td>
<td><p>true</p></td>
<td><p>Should DataFusion support recursive CTEs</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.split_file_groups_by_statistics</p></td>
<td><p>false</p></td>
<td><p>Attempt to eliminate sorts by packing &amp; sorting files with non-overlapping statistics into the same file groups. Currently experimental</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.keep_partition_by_columns</p></td>
<td><p>false</p></td>
<td><p>Should DataFusion keep the columns used for partition_by in the output RecordBatches</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.skip_partial_aggregation_probe_ratio_threshold</p></td>
<td><p>0.8</p></td>
<td><p>Aggregation ratio (number of distinct groups / number of input rows) threshold for skipping partial aggregation. If the value is greater then partial aggregation will skip aggregation for further input</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.skip_partial_aggregation_probe_rows_threshold</p></td>
<td><p>100000</p></td>
<td><p>Number of input rows partial aggregation partition should process, before aggregation ratio check and trying to switch to skipping aggregation mode</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.use_row_number_estimates_to_optimize_partitioning</p></td>
<td><p>false</p></td>
<td><p>Should DataFusion use row number estimates at the input to decide whether increasing parallelism is beneficial or not. By default, only exact row numbers (not estimates) are used for this decision. Setting this flag to <code class="docutils literal notranslate"><span class="pre">true</span></code> will likely produce better plans. if the source of statistics is accurate. We plan to make this the default in the future.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.execution.enforce_batch_size_in_joins</p></td>
<td><p>false</p></td>
<td><p>Should DataFusion enforce batch size in joins or not. By default, DataFusion will not enforce batch size in joins. Enforcing batch size in joins can reduce memory usage when joining large tables with a highly-selective join filter, but is also slightly slower.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.execution.objectstore_writer_buffer_size</p></td>
<td><p>10485760</p></td>
<td><p>Size (bytes) of data buffer DataFusion uses when writing output files. This affects the size of the data chunks that are uploaded to remote object stores (e.g. AWS S3). If very large (&gt;= 100 GiB) output files are being written, it may be necessary to increase this size to avoid errors from the remote end point.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.optimizer.enable_distinct_aggregation_soft_limit</p></td>
<td><p>true</p></td>
<td><p>When set to true, the optimizer will push a limit operation into grouped aggregations which have no aggregate expressions, as a soft limit, emitting groups once the limit is reached, before all rows in the group are read.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.optimizer.enable_round_robin_repartition</p></td>
<td><p>true</p></td>
<td><p>When set to true, the physical plan optimizer will try to add round robin repartitioning to increase parallelism to leverage more CPU cores</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.optimizer.enable_topk_aggregation</p></td>
<td><p>true</p></td>
<td><p>When set to true, the optimizer will attempt to perform limit operations during aggregations, if possible</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.optimizer.enable_dynamic_filter_pushdown</p></td>
<td><p>true</p></td>
<td><p>When set to true attempts to push down dynamic filters generated by operators into the file scan phase. For example, for a query such as <code class="docutils literal notranslate"><span class="pre">SELECT</span> <span class="pre">*</span> <span class="pre">FROM</span> <span class="pre">t</span> <span class="pre">ORDER</span> <span class="pre">BY</span> <span class="pre">timestamp</span> <span class="pre">DESC</span> <span class="pre">LIMIT</span> <span class="pre">10</span></code>, the optimizer will attempt to push down the current top 10 timestamps that the TopK operator references into the file scans. This means that if we already have 10 timestamps in the year 2025 any files that only have timestamps in the year 2024 can be skipped / pruned at various stages in the scan.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.optimizer.filter_null_join_keys</p></td>
<td><p>false</p></td>
<td><p>When set to true, the optimizer will insert filters before a join between a nullable and non-nullable column to filter out nulls on the nullable side. This filter can add additional overhead when the file format does not fully support predicate push down.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.optimizer.repartition_aggregations</p></td>
<td><p>true</p></td>
<td><p>Should DataFusion repartition data using the aggregate keys to execute aggregates in parallel using the provided <code class="docutils literal notranslate"><span class="pre">target_partitions</span></code> level</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.optimizer.repartition_file_min_size</p></td>
<td><p>10485760</p></td>
<td><p>Minimum total files size in bytes to perform file scan repartitioning.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.optimizer.repartition_joins</p></td>
<td><p>true</p></td>
<td><p>Should DataFusion repartition data using the join keys to execute joins in parallel using the provided <code class="docutils literal notranslate"><span class="pre">target_partitions</span></code> level</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.optimizer.allow_symmetric_joins_without_pruning</p></td>
<td><p>true</p></td>
<td><p>Should DataFusion allow symmetric hash joins for unbounded data sources even when its inputs do not have any ordering or filtering If the flag is not enabled, the SymmetricHashJoin operator will be unable to prune its internal buffers, resulting in certain join types - such as Full, Left, LeftAnti, LeftSemi, Right, RightAnti, and RightSemi - being produced only at the end of the execution. This is not typical in stream processing. Additionally, without proper design for long runner execution, all types of joins may encounter out-of-memory errors.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.optimizer.repartition_file_scans</p></td>
<td><p>true</p></td>
<td><p>When set to <code class="docutils literal notranslate"><span class="pre">true</span></code>, datasource partitions will be repartitioned to achieve maximum parallelism. This applies to both in-memory partitions and FileSource’s file groups (1 group is 1 partition). For FileSources, only Parquet and CSV formats are currently supported. If set to <code class="docutils literal notranslate"><span class="pre">true</span></code> for a FileSource, all files will be repartitioned evenly (i.e., a single large file might be partitioned into smaller chunks) for parallel scanning. If set to <code class="docutils literal notranslate"><span class="pre">false</span></code> for a FileSource, different files will be read in parallel, but repartitioning won’t happen within a single file. If set to <code class="docutils literal notranslate"><span class="pre">true</span></code> for an in-memory source, all memtable’s partitions will have their batches repartitioned evenly to the desired number of <code class="docutils literal notranslate"><span class="pre">target_partitions</span></code>. Repartitioning can change the total number of partitions and batches per partition, but does not slice the initial record tables provided to the MemTable on creation.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.optimizer.repartition_windows</p></td>
<td><p>true</p></td>
<td><p>Should DataFusion repartition data using the partitions keys to execute window functions in parallel using the provided <code class="docutils literal notranslate"><span class="pre">target_partitions</span></code> level</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.optimizer.repartition_sorts</p></td>
<td><p>true</p></td>
<td><p>Should DataFusion execute sorts in a per-partition fashion and merge afterwards instead of coalescing first and sorting globally. With this flag is enabled, plans in the form below <code class="docutils literal notranslate"><span class="pre">text</span> <span class="pre">&quot;SortExec:</span> <span class="pre">[a&#64;0</span> <span class="pre">ASC]&quot;,</span> <span class="pre">&quot;</span> <span class="pre">CoalescePartitionsExec&quot;,</span> <span class="pre">&quot;</span> <span class="pre">RepartitionExec:</span> <span class="pre">partitioning=RoundRobinBatch(8),</span> <span class="pre">input_partitions=1&quot;,</span> </code> would turn into the plan below which performs better in multithreaded environments <code class="docutils literal notranslate"><span class="pre">text</span> <span class="pre">&quot;SortPreservingMergeExec:</span> <span class="pre">[a&#64;0</span> <span class="pre">ASC]&quot;,</span> <span class="pre">&quot;</span> <span class="pre">SortExec:</span> <span class="pre">[a&#64;0</span> <span class="pre">ASC]&quot;,</span> <span class="pre">&quot;</span> <span class="pre">RepartitionExec:</span> <span class="pre">partitioning=RoundRobinBatch(8),</span> <span class="pre">input_partitions=1&quot;,</span> </code></p></td>
</tr>
<tr class="row-even"><td><p>datafusion.optimizer.prefer_existing_sort</p></td>
<td><p>false</p></td>
<td><p>When true, DataFusion will opportunistically remove sorts when the data is already sorted, (i.e. setting <code class="docutils literal notranslate"><span class="pre">preserve_order</span></code> to true on <code class="docutils literal notranslate"><span class="pre">RepartitionExec</span></code> and using <code class="docutils literal notranslate"><span class="pre">SortPreservingMergeExec</span></code>) When false, DataFusion will maximize plan parallelism using <code class="docutils literal notranslate"><span class="pre">RepartitionExec</span></code> even if this requires subsequently resorting data using a <code class="docutils literal notranslate"><span class="pre">SortExec</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.optimizer.skip_failed_rules</p></td>
<td><p>false</p></td>
<td><p>When set to true, the logical plan optimizer will produce warning messages if any optimization rules produce errors and then proceed to the next rule. When set to false, any rules that produce errors will cause the query to fail</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.optimizer.max_passes</p></td>
<td><p>3</p></td>
<td><p>Number of times that the optimizer will attempt to optimize the plan</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.optimizer.top_down_join_key_reordering</p></td>
<td><p>true</p></td>
<td><p>When set to true, the physical plan optimizer will run a top down process to reorder the join keys</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.optimizer.prefer_hash_join</p></td>
<td><p>true</p></td>
<td><p>When set to true, the physical plan optimizer will prefer HashJoin over SortMergeJoin. HashJoin can work more efficiently than SortMergeJoin but consumes more memory</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.optimizer.hash_join_single_partition_threshold</p></td>
<td><p>1048576</p></td>
<td><p>The maximum estimated size in bytes for one input side of a HashJoin will be collected into a single partition</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.optimizer.hash_join_single_partition_threshold_rows</p></td>
<td><p>131072</p></td>
<td><p>The maximum estimated size in rows for one input side of a HashJoin will be collected into a single partition</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.optimizer.default_filter_selectivity</p></td>
<td><p>20</p></td>
<td><p>The default filter selectivity used by Filter Statistics when an exact selectivity cannot be determined. Valid values are between 0 (no selectivity) and 100 (all rows are selected).</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.optimizer.prefer_existing_union</p></td>
<td><p>false</p></td>
<td><p>When set to true, the optimizer will not attempt to convert Union to Interleave</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.optimizer.expand_views_at_output</p></td>
<td><p>false</p></td>
<td><p>When set to true, if the returned type is a view type then the output will be coerced to a non-view. Coerces <code class="docutils literal notranslate"><span class="pre">Utf8View</span></code> to <code class="docutils literal notranslate"><span class="pre">LargeUtf8</span></code>, and <code class="docutils literal notranslate"><span class="pre">BinaryView</span></code> to <code class="docutils literal notranslate"><span class="pre">LargeBinary</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.explain.logical_plan_only</p></td>
<td><p>false</p></td>
<td><p>When set to true, the explain statement will only print logical plans</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.explain.physical_plan_only</p></td>
<td><p>false</p></td>
<td><p>When set to true, the explain statement will only print physical plans</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.explain.show_statistics</p></td>
<td><p>false</p></td>
<td><p>When set to true, the explain statement will print operator statistics for physical plans</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.explain.show_sizes</p></td>
<td><p>true</p></td>
<td><p>When set to true, the explain statement will print the partition sizes</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.explain.show_schema</p></td>
<td><p>false</p></td>
<td><p>When set to true, the explain statement will print schema information</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.explain.format</p></td>
<td><p>indent</p></td>
<td><p>Display format of explain. Default is “indent”. When set to “tree”, it will print the plan in a tree-rendered format.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.sql_parser.parse_float_as_decimal</p></td>
<td><p>false</p></td>
<td><p>When set to true, SQL parser will parse float as decimal type</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.sql_parser.enable_ident_normalization</p></td>
<td><p>true</p></td>
<td><p>When set to true, SQL parser will normalize ident (convert ident to lowercase when not quoted)</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.sql_parser.enable_options_value_normalization</p></td>
<td><p>false</p></td>
<td><p>When set to true, SQL parser will normalize options value (convert value to lowercase). Note that this option is ignored and will be removed in the future. All case-insensitive values are normalized automatically.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.sql_parser.dialect</p></td>
<td><p>generic</p></td>
<td><p>Configure the SQL dialect used by DataFusion’s parser; supported values include: Generic, MySQL, PostgreSQL, Hive, SQLite, Snowflake, Redshift, MsSQL, ClickHouse, BigQuery, Ansi, DuckDB and Databricks.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.sql_parser.support_varchar_with_length</p></td>
<td><p>true</p></td>
<td><p>If true, permit lengths for <code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code> such as <code class="docutils literal notranslate"><span class="pre">VARCHAR(20)</span></code>, but ignore the length. If false, error if a <code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code> with a length is specified. The Arrow type system does not have a notion of maximum string length and thus DataFusion can not enforce such limits.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.sql_parser.map_string_types_to_utf8view</p></td>
<td><p>true</p></td>
<td><p>If true, string types (VARCHAR, CHAR, Text, and String) are mapped to <code class="docutils literal notranslate"><span class="pre">Utf8View</span></code> during SQL planning. If false, they are mapped to <code class="docutils literal notranslate"><span class="pre">Utf8</span></code>. Default is true.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.sql_parser.collect_spans</p></td>
<td><p>false</p></td>
<td><p>When set to true, the source locations relative to the original SQL query (i.e. <a class="reference external" href="https://docs.rs/sqlparser/latest/sqlparser/tokenizer/struct.Span.html"><code class="docutils literal notranslate"><span class="pre">Span</span></code></a>) will be collected and recorded in the logical plan nodes.</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.sql_parser.recursion_limit</p></td>
<td><p>50</p></td>
<td><p>Specifies the recursion depth limit when parsing complex SQL Queries</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.format.safe</p></td>
<td><p>true</p></td>
<td><p>If set to <code class="docutils literal notranslate"><span class="pre">true</span></code> any formatting errors will be written to the output instead of being converted into a [<code class="docutils literal notranslate"><span class="pre">std::fmt::Error</span></code>]</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.format.null</p></td>
<td><p></p></td>
<td><p>Format string for nulls</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.format.date_format</p></td>
<td><p>%Y-%m-%d</p></td>
<td><p>Date format for date arrays</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.format.datetime_format</p></td>
<td><p>%Y-%m-%dT%H:%M:%S%.f</p></td>
<td><p>Format for DateTime arrays</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.format.timestamp_format</p></td>
<td><p>%Y-%m-%dT%H:%M:%S%.f</p></td>
<td><p>Timestamp format for timestamp arrays</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.format.timestamp_tz_format</p></td>
<td><p>NULL</p></td>
<td><p>Timestamp format for timestamp with timezone arrays. When <code class="docutils literal notranslate"><span class="pre">None</span></code>, ISO 8601 format is used.</p></td>
</tr>
<tr class="row-even"><td><p>datafusion.format.time_format</p></td>
<td><p>%H:%M:%S%.f</p></td>
<td><p>Time format for time arrays</p></td>
</tr>
<tr class="row-odd"><td><p>datafusion.format.duration_format</p></td>
<td><p>pretty</p></td>
<td><p>Duration format. Can be either <code class="docutils literal notranslate"><span class="pre">&quot;pretty&quot;</span></code> or <code class="docutils literal notranslate"><span class="pre">&quot;ISO8601&quot;</span></code></p></td>
</tr>
<tr class="row-even"><td><p>datafusion.format.types_info</p></td>
<td><p>false</p></td>
<td><p>Show types in visual representation batches</p></td>
</tr>
</tbody>
</table>
</section>
<section id="runtime-configuration-settings">
<h1>Runtime Configuration Settings<a class="headerlink" href="#runtime-configuration-settings" title="Link to this heading">¶</a></h1>
<p>DataFusion runtime configurations can be set via SQL using the <code class="docutils literal notranslate"><span class="pre">SET</span></code> command.</p>
<p>For example, to configure <code class="docutils literal notranslate"><span class="pre">datafusion.runtime.memory_limit</span></code>:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">SET</span><span class="w"> </span><span class="n">datafusion</span><span class="p">.</span><span class="n">runtime</span><span class="p">.</span><span class="n">memory_limit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s1">&#39;2G&#39;</span><span class="p">;</span>
</pre></div>
</div>
<p>The following runtime configuration settings are available:</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>key</p></th>
<th class="head"><p>default</p></th>
<th class="head"><p>description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>datafusion.runtime.memory_limit</p></td>
<td><p>NULL</p></td>
<td><p>Maximum memory limit for query execution. Supports suffixes K (kilobytes), M (megabytes), and G (gigabytes). Example: ‘2G’ for 2 gigabytes.</p></td>
</tr>
</tbody>
</table>
</section>


              </div>
              
              
              <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="sql/prepared_statements.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Prepared Statements</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="explain-usage.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Reading Explain Plans</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
              
          </main>
          

      </div>
    </div>
  
    <script src="../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>
  
<!-- Based on pydata_sphinx_theme/footer.html -->
<footer class="footer mt-5 mt-md-0">
  <div class="container">
    
    <div class="footer-item">
      <p class="copyright">
    &copy; Copyright 2019-2025, Apache Software Foundation.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p class="sphinx-version">
Created using <a href="http://sphinx-doc.org/">Sphinx</a> 8.2.3.<br>
</p>
    </div>
    
    <div class="footer-item">
      <p>Apache DataFusion, Apache, the Apache feather logo, and the Apache DataFusion project logo</p>
      <p>are either registered trademarks or trademarks of The Apache Software Foundation in the United States and other countries.</p>
    </div>
  </div>
</footer>


  </body>
</html>