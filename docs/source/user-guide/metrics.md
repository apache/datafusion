<!---
  Licensed to the Apache Software Foundation (ASF) under one
  or more contributor license agreements.  See the NOTICE file
  distributed with this work for additional information
  regarding copyright ownership.  The ASF licenses this file
  to you under the Apache License, Version 2.0 (the
  "License"); you may not use this file except in compliance
  with the License.  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing,
  software distributed under the License is distributed on an
  "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
  KIND, either express or implied.  See the License for the
  specific language governing permissions and limitations
  under the License.
-->

<!---
This file was generated by the dev/update_metric_docs.sh script.
Do not edit it manually as changes will be overwritten.
Instead, add #[metric_doc] attributes to the metrics and execs you want to document.
-->

# Metrics

DataFusion operators expose runtime metrics so you can understand where time is spent and how much data flows through the pipeline. See more in [EXPLAIN ANALYZE](sql/explain.md#explain-analyze).

## Common Metrics

### BaselineMetrics

Helper for creating and tracking common "baseline" metrics for each operator

| Metric          | Description                                                                                                                                                                                                                                                   |
| --------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| end_time        | end_time is set when `BaselineMetrics::done()` is called                                                                                                                                                                                                      |
| elapsed_compute | amount of time the operator was actively trying to use the CPU                                                                                                                                                                                                |
| output_rows     | output rows: the total output rows                                                                                                                                                                                                                            |
| output_bytes    | Memory usage of all output batches. Note: This value may be overestimated. If multiple output `RecordBatch` instances share underlying memory buffers, their sizes will be counted multiple times. Issue: <https://github.com/apache/datafusion/issues/16841> |
| output_batches  | output batches: the total output batch count                                                                                                                                                                                                                  |

### BuildProbeJoinMetrics

Metrics for build & probe joins

| Metric              | Description                                                         |
| ------------------- | ------------------------------------------------------------------- |
| baseline            |                                                                     |
| build_time          | Total time for collecting build-side of join                        |
| build_input_batches | Number of batches consumed by build-side                            |
| build_input_rows    | Number of rows consumed by build-side                               |
| build_mem_used      | Memory used by build-side in bytes                                  |
| join_time           | Total time for joining probe-side batches to the build-side batches |
| input_batches       | Number of batches consumed by probe-side of this operator           |
| input_rows          | Number of rows consumed by probe-side this operator                 |
| probe_hit_rate      | Fraction of probe rows that found more than one match               |
| avg_fanout          | Average number of build matches per matched probe row               |

### PruningMetrics

Counters tracking pruning metrics

| Metric  | Description |
| ------- | ----------- |
| pruned  |             |
| matched |             |

### RatioMetrics

Counters tracking ratio metrics (e.g. matched vs total)

| Metric         | Description |
| -------------- | ----------- |
| part           |             |
| total          |             |
| merge_strategy |             |

### SpillMetrics

Helper for creating and tracking spill-related metrics for each operator

| Metric           | Description                                                               |
| ---------------- | ------------------------------------------------------------------------- |
| spill_file_count | count of spills during the execution of the operator                      |
| spilled_bytes    | total bytes actually written to disk during the execution of the operator |
| spilled_rows     | total spilled rows during the execution of the operator                   |

### SplitMetrics

Metrics for tracking batch splitting activity

| Metric        | Description                                        |
| ------------- | -------------------------------------------------- |
| batches_split | Number of times an input [`RecordBatch`] was split |

## Operator-specific Metrics

### AggregateExec

Hash aggregate execution plan

#### GroupByMetrics

| Metric                     | Description                                                                                                                                                                                                 |
| -------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| time_calculating_group_ids | Time spent calculating the group IDs from the evaluated grouping columns.                                                                                                                                   |
| aggregate_arguments_time   | Time spent evaluating the inputs to the aggregate functions.                                                                                                                                                |
| aggregation_time           | Time spent evaluating the aggregate expressions themselves (e.g. summing all elements and counting number of elements for `avg` aggregate).                                                                 |
| emitting_time              | Time spent emitting the final results and constructing the record batch which includes finalizing the grouping expressions (e.g. emit from the hash table in case of hash aggregation) and the accumulators |

### CrossJoinExec

Cross Join Execution Plan

_No operator-specific metrics documented (see Common Metrics)._

### DataSourceExec

[`ExecutionPlan`] that reads one or more files

#### FileStreamMetrics

Metrics for [`FileStream`]

| Metric                   | Description                                                                                                                                                                                                                                                                                                                                                                                                                                                                |
| ------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| time_opening             | Wall clock time elapsed for file opening. Time between when [`FileOpener::open`] is called and when the [`FileStream`] receives a stream for reading. If there are multiple files being scanned, the stream will open the next file in the background while scanning the current file. This metric will only capture time spent opening while not also scanning. [`FileStream`]: <https://github.com/apache/datafusion/blob/main/datafusion/datasource/src/file_stream.rs> |
| time_scanning_until_data | Wall clock time elapsed for file scanning + first record batch of decompression + decoding Time between when the [`FileStream`] requests data from the stream and when the first [`RecordBatch`] is produced. [`FileStream`]: <https://github.com/apache/datafusion/blob/main/datafusion/datasource/src/file_stream.rs>                                                                                                                                                    |
| time_scanning_total      | Total elapsed wall clock time for scanning + record batch decompression / decoding Sum of time between when the [`FileStream`] requests data from the stream and when a [`RecordBatch`] is produced for all record batches in the stream. Note that this metric also includes the time of the parent operator's execution.                                                                                                                                                 |
| time_processing          | Wall clock time elapsed for data decompression + decoding Time spent waiting for the FileStream's input.                                                                                                                                                                                                                                                                                                                                                                   |
| file_open_errors         | Count of errors opening file. If using `OnError::Skip` this will provide a count of the number of files which were skipped and will not be included in the scan results.                                                                                                                                                                                                                                                                                                   |
| file_scan_errors         | Count of errors scanning file If using `OnError::Skip` this will provide a count of the number of files which were skipped and will not be included in the scan results.                                                                                                                                                                                                                                                                                                   |

### FilterExec

FilterExec evaluates a boolean predicate against all input batches to determine which rows to include in its output batches.

#### FilterExecMetrics

The metrics for `FilterExec`

| Metric           | Description                                                       |
| ---------------- | ----------------------------------------------------------------- |
| baseline_metrics | Common metrics for most operators                                 |
| selectivity      | Selectivity of the filter, calculated as output_rows / input_rows |

### HashJoinExec

Join execution plan: Evaluates equijoin predicates in parallel on multiple partitions using a hash table and an optional filter list to apply post join.

_No operator-specific metrics documented (see Common Metrics)._

### NestedLoopJoinExec

NestedLoopJoinExec is a build-probe join operator designed for joins that do not have equijoin keys in their `ON` clause.

#### NestedLoopJoinMetrics

| Metric       | Description                                                      |
| ------------ | ---------------------------------------------------------------- |
| join_metrics | Join execution metrics                                           |
| selectivity  | Selectivity of the join: output_rows / (left_rows \* right_rows) |

### PiecewiseMergeJoinExec

`PiecewiseMergeJoinExec` is a join execution plan that only evaluates single range filter and show much better performance for these workloads than `NestedLoopJoin`

_No operator-specific metrics documented (see Common Metrics)._

### RepartitionExec

Maps `N` input partitions to `M` output partitions based on a [`Partitioning`] scheme.

#### RepartitionMetrics

| Metric           | Description                                                                               |
| ---------------- | ----------------------------------------------------------------------------------------- |
| fetch_time       | Time in nanos to execute child operator and fetch batches                                 |
| repartition_time | Repartitioning elapsed time in nanos                                                      |
| send_time        | Time in nanos for sending resulting batches to channels. One metric per output partition. |

### SortExec

Sort execution plan.

#### ExternalSorterMetrics

| Metric        | Description |
| ------------- | ----------- |
| baseline      | metrics     |
| spill_metrics |             |

#### TopKMetrics

| Metric           | Description                                      |
| ---------------- | ------------------------------------------------ |
| baseline         | metrics                                          |
| row_replacements | count of how many rows were replaced in the heap |

### SortMergeJoinExec

Join execution plan that executes equi-join predicates on multiple partitions using Sort-Merge join algorithm and applies an optional filter post join. Can be used to join arbitrarily large inputs where one or both of the inputs don't fit in the available memory.

#### SortMergeJoinMetrics

Metrics for SortMergeJoinExec

| Metric           | Description                                                                                   |
| ---------------- | --------------------------------------------------------------------------------------------- |
| join_time        | Total time for joining probe-side batches to the build-side batches                           |
| input_batches    | Number of batches consumed by this operator                                                   |
| input_rows       | Number of rows consumed by this operator                                                      |
| baseline_metrics | Execution metrics                                                                             |
| peak_mem_used    | Peak memory used for buffered data. Calculated as sum of peak memory values across partitions |
| spill_metrics    | Metrics related to spilling                                                                   |

### SymmetricHashJoinExec

A symmetric hash join with range conditions is when both streams are hashed on the join key and the resulting hash tables are used to join the streams. The join is considered symmetric because the hash table is built on the join keys from both streams, and the matching of rows is based on the values of the join keys in both streams. This type of join is efficient in streaming context as it allows for fast lookups in the hash table, rather than having to scan through one or both of the streams to find matching rows, also it only considers the elements from the stream that fall within a certain sliding window (w/ range conditions), making it more efficient and less likely to store stale data. This enables operating on unbounded streaming data without any memory issues.

#### StreamJoinMetrics

Metrics for HashJoinExec

| Metric              | Description                                            |
| ------------------- | ------------------------------------------------------ |
| left                | Number of left batches/rows consumed by this operator  |
| right               | Number of right batches/rows consumed by this operator |
| stream_memory_usage | Memory used by sides in bytes                          |
| baseline_metrics    | Number of rows produced by this operator               |

### UnnestExec

Unnest the given columns (either with type struct or list) For list unnesting, each row is vertically transformed into multiple rows For struct unnesting, each column is horizontally transformed into multiple columns, Thus the original RecordBatch with dimension (n x m) may have new dimension (n' x m')

#### UnnestMetrics

| Metric           | Description                |
| ---------------- | -------------------------- |
| baseline_metrics | Execution metrics          |
| input_batches    | Number of batches consumed |
| input_rows       | Number of rows consumed    |
